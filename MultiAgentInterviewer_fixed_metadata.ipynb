{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1yAk9KMOQqEB",
        "XbOmutbjQ562"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },  
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -qU langchain==0.3.27 langchain-mistralai==0.2.12 python-dotenv==1.1.1 langgraph==0.2.19 mistralai faiss-cpu==1.13.2 sentence-transformers==5.2.2 pymorphy3 rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpRv8GtbT_Hq",
        "outputId": "fccb024c-d7ad-465a-8fec-510f8c9e6c04"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.3.83 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langgraph-checkpoint<5.0.0,>=2.1.0, but you have langgraph-checkpoint 1.0.12 which is incompatible.\n",
            "google-adk 1.23.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.23.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/avidale/encodechka\n",
        "!pip install -r encodechka/requirements.txt\n",
        "!pip install transformers sentencepiece sentence-transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QixYyzgfhPr-",
        "outputId": "70feb740-e8fb-41bc-a03a-508be55e490c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'encodechka'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 117 (delta 50), reused 22 (delta 11), pack-reused 26 (from 1)\u001b[K\n",
            "Receiving objects: 100% (117/117), 2.76 MiB | 13.71 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 1)) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 5)) (4.67.1)\n",
            "Collecting razdel (from -r encodechka/requirements.txt (line 6))\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r encodechka/requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r encodechka/requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r encodechka/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r encodechka/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r encodechka/requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r encodechka/requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r encodechka/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r encodechka/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r encodechka/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r encodechka/requirements.txt (line 1)) (3.0.3)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "MISTRAL_API_KEY = userdata.get(\"MISTRAL_API_KEY\")"
      ],
      "metadata": {
        "id": "L9ZZMMbyUESd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG\n",
        "------"
      ],
      "metadata": {
        "id": "1yAk9KMOQqEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import TypedDict, Annotated, List, Dict, Any\n",
        "from datetime import datetime\n",
        "from langgraph.graph import StateGraph, END\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai import Mistral\n",
        "import operator\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import re\n",
        "import pymorphy3\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers  import CrossEncoder\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "\n",
        "class RetrieverAgent:\n",
        "    def __init__(self, docs):\n",
        "        self.docs = docs\n",
        "        self.model = SentenceTransformer('deepvk/USER-bge-m3')\n",
        "        self.cross_encoder = CrossEncoder('PitKoro/cross-encoder-ru-msmarco-passage')\n",
        "        # везде добавил нормализацию векторов\n",
        "        # сравниваю вектора по косинусному сходству а не евклидову расстоянию. так привычней :)\n",
        "        emb = self.model.encode(docs, normalize_embeddings=True)\n",
        "        self.index = faiss.IndexFlatIP(emb.shape[1])\n",
        "        self.index.add(emb)\n",
        "        self.morph = pymorphy3.MorphAnalyzer()\n",
        "        # Токенизируем\n",
        "        tokenized_docs = [self._tokenize_with_lemmatization(doc) for doc in docs]\n",
        "        self.bm25 = BM25Okapi(tokenized_docs)\n",
        "\n",
        "    # токенизация для bm25\n",
        "    def _tokenize(self, text):\n",
        "        text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text) # Разделяем CamelCase слова\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s-]', ' ', text) # Удаляем все, кроме букв, цифр, пробелов и дефисов\n",
        "        tokens = text.split() # Разбиваем по пробелам\n",
        "\n",
        "        # оставляем токены, содержащие хотя бы одну букву\n",
        "        tokens = [token for token in tokens if any(c.isalpha() for c in token)]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _tokenize_with_lemmatization(self, text):\n",
        "        tokens = self._tokenize(text)\n",
        "        lemmas = []\n",
        "        for token in tokens:\n",
        "            parsed = self.morph.parse(token)[0]\n",
        "            lemmas.append(parsed.normal_form)\n",
        "        return lemmas\n",
        "      # после этого \"машинного обучения\" → [\"машинный\", \"обучение\"]\n",
        "\n",
        "    def search(self, query, k=3, rerank_k=10, bm25_weight=0.25):\n",
        "        \"\"\"\n",
        "            k: количество возвращаемых документов (после реранжирования) с помощью CrossEncoder (итоговый ответ)\n",
        "            rerank_k: сколько документов отбирать для реранжирования с помощью SentenceTransformer и bm25\n",
        "            bm25_weight: доля документов, отобранных bm25, от общего количества документов rerank_k\n",
        "\n",
        "            Мы отбираем документы двумя методами:\n",
        "            1) Семантический поиск с помощью би-энкодера\n",
        "            2) По ключевым словам с помощью bm25\n",
        "\n",
        "            Далее отобранные документы подаем для финального реранжирования в CrossEncoder.\n",
        "            Таким образом значительно увеличиваем точность RAG для большего числа документов.\n",
        "        \"\"\"\n",
        "        # Получаем кандидатов от BM25\n",
        "        tokenized_query = self._tokenize_with_lemmatization(query)\n",
        "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
        "        bm25_top_n = int(rerank_k * bm25_weight)\n",
        "        bm25_indices = np.argsort(bm25_scores)[::-1][:bm25_top_n] # массив индексов отобранных статей с помощью bm25\n",
        "\n",
        "       # Получаем кандидатов от би-энкодера\n",
        "        q_emb = self.model.encode([query], normalize_embeddings=True)\n",
        "        bi_top_n = rerank_k - bm25_top_n\n",
        "        _, bi_indices = self.index.search(q_emb, min(bi_top_n, len(self.docs)))\n",
        "        bi_indices = bi_indices[0] # массив индексов отобранных статей с помощью bi-encoder\n",
        "\n",
        "\n",
        "        # Объединяем кандидатов + убираем дубликаты\n",
        "        combined_indices = list(set(bm25_indices.tolist() + bi_indices.tolist()))\n",
        "        combined_indices = combined_indices[:rerank_k]\n",
        "\n",
        "        # защита от дурака\n",
        "        if len(combined_indices) == 0:\n",
        "            return []\n",
        "        if rerank_k <= k or self.cross_encoder is None:\n",
        "            return [self.docs[i] for i in combined_indices[:k]]\n",
        "\n",
        "       # Реранжирование кросс-энкодером\n",
        "        candidate_docs = [self.docs[i] for i in combined_indices]\n",
        "        pairs = [(query, doc) for doc in candidate_docs]\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "\n",
        "        sorted_indices = np.argsort(scores)[::-1]\n",
        "        final_docs = []\n",
        "        seen_docs = set()\n",
        "\n",
        "        for idx_in_candidates in sorted_indices:\n",
        "            if len(final_docs) >= k:\n",
        "                break\n",
        "\n",
        "            original_idx = combined_indices[idx_in_candidates]\n",
        "            doc_text = self.docs[original_idx]\n",
        "\n",
        "            # Простая дедупликация по началу текста\n",
        "            doc_start = doc_text[:100]\n",
        "            if doc_start not in seen_docs:\n",
        "                seen_docs.add(doc_start)\n",
        "                final_docs.append(doc_text)\n",
        "\n",
        "        return final_docs\n",
        "\n",
        "client = Mistral(api_key=MISTRAL_API_KEY)\n",
        "\n",
        "class RagSystem:\n",
        "    \"\"\"RAG система с чанкованием документов\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.expert_rag = None\n",
        "        self.manager_rag = None\n",
        "\n",
        "    def initialize_from_csv(self, expert_csv_path: str = None,\n",
        "                           manager_csv_path: str = None,\n",
        "                           text_column: str = 'text',\n",
        "                           chunk_size: int = 500,\n",
        "                           overlap: int = 100):\n",
        "        \"\"\"\n",
        "        Инициализирует RAG системы из CSV файлов с чанкованием\n",
        "        \"\"\"\n",
        "        expert_chunks, expert_metadata = [], []\n",
        "        manager_chunks, manager_metadata = [], []\n",
        "\n",
        "        # Загрузка и обработка документов для эксперта\n",
        "        if expert_csv_path:\n",
        "            expert_docs = self._load_csv(expert_csv_path, text_column)\n",
        "            if expert_docs:\n",
        "                expert_chunks, expert_metadata = self._chunk_documents(\n",
        "                    expert_docs, chunk_size, overlap\n",
        "                )\n",
        "                self.expert_rag = RetrieverAgent(expert_chunks)\n",
        "                print(f\"[RAG] Эксперт: создано {len(expert_chunks)} чанков\")\n",
        "\n",
        "        # Загрузка и обработка документов для менеджера\n",
        "        if manager_csv_path:\n",
        "            manager_docs = self._load_csv(manager_csv_path, text_column)\n",
        "            if manager_docs:\n",
        "                manager_chunks, manager_metadata = self._chunk_documents(\n",
        "                    manager_docs, chunk_size, overlap\n",
        "                )\n",
        "                self.manager_rag = RetrieverAgent(manager_chunks)\n",
        "                print(f\"[RAG] Менеджер: создано {len(manager_chunks)} чанков\")\n",
        "\n",
        "    def _load_csv(self, csv_path: str, text_column: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Загружает документы из CSV файла\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            documents = []\n",
        "\n",
        "            for idx, row in df.iterrows():\n",
        "                doc = {\n",
        "                    'text': str(row[text_column]),\n",
        "                    'metadata': {\n",
        "                        'source': csv_path,\n",
        "                        'row_id': idx,\n",
        "                        **{col: str(row[col]) for col in df.columns if col != text_column}\n",
        "                    }\n",
        "                }\n",
        "                documents.append(doc)\n",
        "\n",
        "            print(f\"[RAG] Загружено {len(documents)} документов из {csv_path}\")\n",
        "            return documents\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[RAG] Ошибка загрузки CSV: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _chunk_documents(self, documents: List[Dict[str, Any]],\n",
        "                        chunk_size: int = 500,\n",
        "                        overlap: int = 100) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
        "        \"\"\"\n",
        "        Разбивает документы на чанки с перекрытием\n",
        "\n",
        "        Returns:\n",
        "            Кортеж: (список текстов чанков, список метаданных чанков)\n",
        "        \"\"\"\n",
        "        all_chunks = []\n",
        "        all_metadata = []\n",
        "\n",
        "        for doc in documents:\n",
        "            text = doc['text']\n",
        "            base_metadata = doc['metadata']\n",
        "\n",
        "            # Разбиваем на чанки с перекрытием\n",
        "            chunks = self._split_text_with_overlap(text, chunk_size, overlap)\n",
        "\n",
        "            for i, chunk_text in enumerate(chunks):\n",
        "                all_chunks.append(chunk_text)\n",
        "\n",
        "                # Создаем метаданные для чанка\n",
        "                chunk_metadata = {\n",
        "                    **base_metadata,\n",
        "                    'chunk_id': i,\n",
        "                    'total_chunks': len(chunks),\n",
        "                    'chunk_size': len(chunk_text)\n",
        "                }\n",
        "                all_metadata.append(chunk_metadata)\n",
        "\n",
        "        return all_chunks, all_metadata\n",
        "\n",
        "    def _split_text_with_overlap(self, text: str, chunk_size: int, overlap: int) -> List[str]:\n",
        "        \"\"\"Разбивает текст на чанки с перекрытием\"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        text_length = len(text)\n",
        "\n",
        "        while start < text_length:\n",
        "            end = start + chunk_size\n",
        "\n",
        "            if end < text_length:\n",
        "                for boundary in ['. ', '! ', '? ', '\\n\\n', '\\n', ' ']:\n",
        "                    pos = text.rfind(boundary, start, end)\n",
        "                    if pos != -1 and pos > start + chunk_size * 0.5:\n",
        "                        end = pos + len(boundary)\n",
        "                        break\n",
        "\n",
        "            chunks.append(text[start:end].strip())\n",
        "\n",
        "            start = end - overlap if end - overlap > start else end\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def search_expert_rag(self, query: str, k: int = 3) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Поиск в базе эксперта с возвратом лучших чанков\"\"\"\n",
        "        if not self.expert_rag:\n",
        "            return []\n",
        "\n",
        "        results = self.expert_rag.search(query, k=k*2, rerank_k=20)\n",
        "\n",
        "        grouped_results = {}\n",
        "        return results[:k]\n",
        "\n",
        "    def search_manager_rag(self, query: str, k: int = 3) -> List[str]:\n",
        "        \"\"\"Поиск в базе менеджера\"\"\"\n",
        "        if not self.manager_rag:\n",
        "            return []\n",
        "\n",
        "        return self.manager_rag.search(query, k=k, rerank_k=15)\n"
      ],
      "metadata": {
        "id": "G2xiESpE84V6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструменты\n",
        "----------"
      ],
      "metadata": {
        "id": "XbOmutbjQ562"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InternetSearch:\n",
        "    \"\"\"Инструмент для поиска в интернете\"\"\"\n",
        "\n",
        "    def __init__(self, api_key=None):\n",
        "        self.api_key = api_key\n",
        "        # Можно использовать различные API:\n",
        "        # - SerpAPI (Google Search)\n",
        "        # - Google Custom Search API\n",
        "        # - Brave Search API\n",
        "        # В примере - заглушка для демонстрации\n",
        "\n",
        "    def search_web(self, query, num_results=3):\n",
        "        \"\"\"Поиск информации в интернете\"\"\"\n",
        "        try:\n",
        "            # Пример с SerpAPI (раскомментировать при наличии ключа)\n",
        "            # params = {\n",
        "            #     'api_key': self.api_key,\n",
        "            #     'q': query,\n",
        "            #     'num': num_results,\n",
        "            #     'engine': 'google'\n",
        "            # }\n",
        "            # response = requests.get('https://serpapi.com/search', params=params)\n",
        "            # results = response.json().get('organic_results', [])\n",
        "\n",
        "            # Заглушка для демонстрации\n",
        "            results = [\n",
        "                {\n",
        "                    \"title\": f\"Результат поиска: {query}\",\n",
        "                    \"snippet\": f\"Информация по запросу '{query}' из интернета.\",\n",
        "                    \"link\": \"https://example.com\"\n",
        "                }\n",
        "                for _ in range(num_results)\n",
        "            ]\n",
        "\n",
        "            formatted_results = []\n",
        "            for r in results:\n",
        "                formatted_results.append(f\"{r.get('title', '')}: {r.get('snippet', '')}\")\n",
        "\n",
        "            return \"\\n\".join(formatted_results)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"[ОШИБКА ПОИСКА]: {str(e)}\"\n",
        "\n",
        "\n",
        "def with_tools(func):\n",
        "    \"\"\"Декоратор, добавляющий инструменты к функции агента\"\"\"\n",
        "    def wrapper(state: InterviewState, *args, **kwargs):\n",
        "        if 'tools' not in state:\n",
        "            state['tools'] = {}\n",
        "\n",
        "        # Вызываем оригинальную функцию\n",
        "        return func(state, *args, **kwargs)\n",
        "    return wrapper\n",
        "\n",
        "# Создаем глобальные инструменты\n",
        "rag_system = RagSystem()\n",
        "internet_search = InternetSearch()\n",
        "\n",
        "def initialize_rag_system():\n",
        "    \"\"\"Инициализация RAG системы из CSV файлов\"\"\"\n",
        "    rag_system = RagSystem()\n",
        "\n",
        "    expert_csv = \"expert_knowledge.csv\"\n",
        "    manager_csv = \"manager_knowledge.csv\"\n",
        "\n",
        "    try:\n",
        "        rag_system.initialize_from_csv(\n",
        "            expert_csv_path=expert_csv,\n",
        "            manager_csv_path=manager_csv,\n",
        "            text_column='text',\n",
        "            chunk_size=500,\n",
        "            overlap=100\n",
        "        )\n",
        "        return rag_system\n",
        "    except Exception as e:\n",
        "        print(f\"[ОШИБКА RAG] Не удалось инициализировать систему: {e}\")\n",
        "        return rag_system\n",
        "\n",
        "# Глобальная RAG система\n",
        "rag_system = initialize_rag_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822,
          "referenced_widgets": [
            "e18cc1f759d44014b81a17b273c3f589",
            "072b902eee0a410aa9656958298aeb85",
            "d45e04361b7740e78739b3c0e86384b9",
            "7c325ada58144625b46f4e364a976a9e",
            "f8763ac1809d4b61b76b880673c69272",
            "b42756a1b3ee4081b47b55e55007cec0",
            "90751b52c935446a8fb0f5648f49e01a",
            "341c8fd00b3b4f58b2e56363c388bd5d",
            "32024f8d99284d4f9cb0f5cb1a8a938e",
            "81f7faf123a64ac1ac875e69cbe4934c",
            "ac8f5f15fa4e409a80c497174ab4061f",
            "c9fe29d3a306495ca050a9d3dcf35812",
            "f01c01b025394202b8c3bb5318850bd2",
            "1bf84c7b7f20458fad934315846a06f0",
            "8880c1888d9c43db90bda3aad5f8c888",
            "88123fb581024740a7204ff10cf25988",
            "94f37b02d3fb4c97adb433fe3ad8bae7",
            "b98fe5147ce744ee888c9d970062f8ab",
            "5828c72e2c934e55abd2879e882a7f41",
            "1427df6215444850a81416d37ebf7e17",
            "ce74178dc6f84c118a96128ddda8fad0",
            "6ff2b806a55744aabf374f59417571dc",
            "3c985b5f1f5f43a99ad5ed9f0f10da81",
            "ffac46ee9c4047b089d1487216b8d930",
            "2021d52f58044aac8b98365de5cd7323",
            "69c7773968634a068c4224b7168ad34a",
            "6e3d2fddbe764f30a75441646474b346",
            "040b65a7d87d4bfdb79e78ef8bbc264e",
            "52cd26f3dbda46bca42647b62daa4b63",
            "843502e28830474ca704039979da09db",
            "3eaf802d821a4d889a3ada1e6694438b",
            "9a6757062d114f9991aa7bafa6ddfd0e",
            "d9bceb502a4f4f11bc7d5d4d132219f5",
            "de3e4b19474c422d867dc2de2f7c9a66",
            "3eb0f6fceb074fc988d25e1a6c988dce",
            "d02b26ce2b8c4e278c34b96d2bc095c3",
            "b50849c341634bf2af073b247fc0da6d",
            "d24a89b1ca6c43b888770b2dd35074f6",
            "ad2ebfc401f947ad91531faa7578af0f",
            "f6dd9a3b60884b83831793376a443ac3",
            "7ef8799c16e04ef4bff3e84e75c852e6",
            "956a247e759a482589b51a6a6e4b88eb",
            "de5a32ba518349ce9e0497961a02684f",
            "a1772bbd18994ff78d30604c1b56ca4e",
            "0dc9ba726c98495eb6e77ef91b6c1dfd",
            "26c44775e61f48c282e09a81b43f411d",
            "2f05a68425ad4cb795886d4e1c26025c",
            "5c62fd8b61934e00b0c5ab2d8cdb1e83",
            "370854ab7c004784bbdb44e80aa9743f",
            "6b793ef682ee4aa582b00ab43adf42c6",
            "8d135b139c6e4abba349320e079a21a1",
            "afc617a283ab4efb9449c89803901527",
            "12b9bdf82f9146eaae90835c7c2c964f",
            "8f340e4832a8429c9518e2709fca91f7",
            "ad5a37b9dfa44ca78cf70d162175d7b8",
            "62cd67d0fbab464daf437299d09a2e95",
            "975805e404ac40c0bd414ef066a9f5fc",
            "9639a5dc452c4388b9b171cec14f7d40",
            "87bb252d2929431b87622680f0a41753",
            "574ca226fd7449f9aab9ccbc7afec513",
            "5b2cbe515f874b64849bbaa2359017f0",
            "74048bc90acd4c4c85c9bea27fd36b7a",
            "78738e13f4c9471ca255e3f7584c98cd",
            "ea05ad8995024293a959bceb5e0ae3ec",
            "3749357ba752497485d971b69ed7886d",
            "495278356a774737ad24a3a7dd71e7e5",
            "51862d7cfb72452eb4373849fea95bf0",
            "da895e8b2bbc44dd9e9b9a6cd3f4913a",
            "e5479034ace04dd9a5af57ec794f5b93",
            "a18a5b063118401098ed8bcc8bc4ee05",
            "94e932b8efa241f2afa7dd71aad4fb07",
            "f0ada9d5e69b4977a5454f0e959bfd12",
            "d902211cf2934b5bbb50ecbb0c2f8860",
            "95e2188a3f384cb388c488c547789d04",
            "31090d448344443a9fb009ca55fb5cd5",
            "c8a6255a25da44b495b7a5bebaf8833e",
            "65f1c839adbc45799083eaec1367981d",
            "77410f268fc8444d91b9828e0786dd09",
            "878b53eef9e94346af125c38265be83b",
            "0b97e955a9104e1a90f0cfbe71ad4612",
            "795ae05f2ce441fd8e1bc0a074fdfb51",
            "b1c2178a482b44d1bd201d4f683ebe43",
            "0959fbf769334d72bad51c7cffb0e076",
            "10c0331a8e5a40a5aca7dd2e985a84f3",
            "377b008e0f1643eb9e0196283404dc04",
            "9298fd53807342a5855001a7bda5091b",
            "57db2738e05949a188c9fa09accbe161",
            "e95accc7d8994810940e7641a7146910",
            "8b3622a70749444c9e828d4c34d683dd",
            "f310097b70024649a0e08bc22c1b9820",
            "c176d98d10df4e8490074f5eb9165bbd",
            "ae39b089afd94e998c0b9e185318a5d7",
            "406c57538bc244bcb6d2be532f50e21c",
            "39256ea400234b32bc1a20c0326eadfa",
            "1d05fef1b2844d54806a5822d603d270",
            "aedfbb15c8ed45e280e2f281941b669d",
            "8d573728ea364d86b0ab469c715ef517",
            "5a02ce7187bf42b0a4ec525e78645bc4",
            "3854e35d636f4fcabbf1ea24e8070270",
            "e8a6226bdbe5449c8c5039f211fa7516",
            "7916a3d95d1243fe87276b49b2af8197",
            "7e8c81c2a40e4e54816c62f1180bfa84",
            "2bc21805a0c441a7900af0943b26f8ed",
            "f64cf321df4c4ca7b0219acf425250d0",
            "0d397268e9144d81b43efeb111c4a54c",
            "86ad33dfadea47cba3d0e69d630452d3",
            "ec9fd262b4284606a7d840f13e23bd45",
            "5e21134f67614f8db234f67792cd6e9e",
            "705c3a9faf3d4b9994f22c4729067325",
            "94a686745e1246d7896fe246382cd737",
            "19acb04f278f471c8255869e76d04d15",
            "b6cbe61af854412c837a25f79104bbdb",
            "13fd2f79ef224086b0e4d7b3a8b9bb82",
            "e9e0c77d5c8c42889e6f31d21cbf322f",
            "49a2c50785124e429894c66ed9969ed0",
            "46badac3387a452a88f3bf195b62cdd3",
            "a565d631c5cd49e39bf70d1d76722e74",
            "05f0499b2fd04b41affe558857039aeb",
            "12de88ab876047b3a4632f348c0150fe",
            "40644ba57d304a56a69fce19569749b1",
            "7500160835c340569bdb34b7d4940f3e",
            "b4491a0768124a80b428132b0039bd99",
            "d823266b409c4af3a6da0367b6b50661",
            "79e314fc44f9464e88e09964175a278f",
            "756d824006ff4cc2be9895f5a5338c3b",
            "a4038db41581417a972edd168b469ce4",
            "1f8d3f882f534022a28de745aba561a5",
            "0079c944a0134df699a8010e425549c2",
            "55e32ac60dd34cb0b666323b6467ed5e",
            "5cbbd8f8b64e42768e022c0a11ef0112",
            "6c362ef1ca154b898f8beee080a7a75f",
            "03a3fe7063fe4991af3122e417ed850f",
            "05740f17a95d45a88421c801c67ef580",
            "f763d043c82643659b209ed0774837f4",
            "83fdfcb3f4da4eaabab52a7fd3aea540",
            "1731ff13c120497d8e1347faa59cae29",
            "2066db1407d94df88cfbcd95d5ea0312",
            "7d77ac87a54241799001a9c1c105ed45",
            "a90fc7ed76f64ad690e3bb3a642a4001",
            "59fb1de593a64d5e824c3de61088a559",
            "dab31cd758fd4294b7f1dc8e574ab979",
            "5a4630de6a39471ba75d284979a9e7b2",
            "5292d98bdd7b4cec95dda9053668b074",
            "6724ae49bef14e6198aa9e93063fade8",
            "dbae24665c4149268f6f84bd3331b2b5",
            "c237ee0c40b7496eb4bcf8def4fdb4bc",
            "18279e3c5b3f481ca417bdf77956c301",
            "0d0c4a48bfcd46f38a2681170725b799",
            "b8af9067f6784b7685523f4f1489696e",
            "4e664cc395a3446a9d7faa748a9862f9",
            "d64b03ba21cb45fe9cb53f71ae9b9004",
            "31bcc66de7a24c8d892fca2eb8015b62",
            "7668954a6e6844989fc5ae8af4fc5eeb",
            "4e7a3a89a2884a169b29ed8fed77a228",
            "667a8d4474194d0fae1993b67f83d94f",
            "d5559dd14c0e43f886781f097d26276f",
            "c7787d0c518942f681778a1d9a2360d5",
            "1d910c60749e4b9baa8cf006b9dac7c9",
            "73b7adc0a5eb4dc8a72ae044b4b8cdd5",
            "8bb19b7fab784eb4a18439b1b95ac4a0",
            "3bad4e899cd540439007318127207407",
            "772eb28ccee048469646ccf12aac71b4",
            "9258a50715f64ca0ac8628a421a14cb1",
            "bd615a5ed8f947bcba79267718798936",
            "87b88d58933d4c33891aea2aba4d3201",
            "7e240c6bc1ee4179adc928eb01adb047",
            "68c51e2cfb114c33b87615d263e39b1a",
            "3a7815e420624b6f9569a607935dc64d",
            "e762673658ac46d086bad8bf06a23631",
            "ec2d67353c4042659421a4de6a996edc",
            "17152a6b15b34736831ac6e587388ada",
            "73061a8ae7c0458d983dda42c4e8c4d4",
            "85f1b53d4fe5463293e4e5cc62576a55",
            "8f8dcfca016a418aab84a40ad8fb4682",
            "36c0206ecc2e4258abb7c8e653e4eef0",
            "9f66d0c12f4544ef94505f63a7fc2781",
            "9a4492b2601f42048a38312efecd8c16",
            "19231e6ed4cf467a8147ca7db5b84bda",
            "d346f3f6850040b89dad3899b1eef3cf",
            "b1fb62f3b8d54bfba44271f0b0400a35",
            "04b751682ced4fb093dbb1c531a7130d",
            "f72939add94041829d12da4b4cdf8747",
            "be3b257ac8724a178d77b0a5c9bae44d",
            "5054d38e0fb54c7b96194fe87e9d00e1",
            "11f37717258c4328b13cf693b46a1b66",
            "bc421fe766164604986a2554999b9c33",
            "629e18d8bc8f4eb096c02bb032e7ca37",
            "04a0379e92b2486283e41c287726e315",
            "10e51d02a0884077ae1f3a3d401db945",
            "9d10b3e4dc4b4a03a7b9838295b85611",
            "dc5b551546ef4f5782c0e7c2d7024854",
            "70c849afcc3a44fb80c0553a1a6ec89c",
            "48d43db12f514aa89f32c8d3848ce238",
            "f2fef49262bb4c9a99d1b0dc1a54a14e",
            "13161887e02f4358b00aa7b6c2fb1b99",
            "f628c27476f54fa99e7e8d255231d53e",
            "72f49a1908364d3eaa052f80104e0281",
            "83714574e72646b9b36b6d2b21663201",
            "89fc410b66014018abb0ad424e3afe52",
            "4f117af53a554ee783dd3025ea8e4203",
            "341fb22ea0224e77990df52079cc7cd5",
            "9d5a3a3e08d94bc69a634b4330a2ac94",
            "2ec3a092de4d42d49cbf8a50fadb4838",
            "d3b4835191014dbf9c8173d4ca081b2c",
            "db581dd301fd41c4868e2b2e4729f0e4",
            "1c0fc704726c496a9c68fccf4e9bb963",
            "5a504964ec4941afaaec2ac753c2201b",
            "96ad7402563449789351323f5cb2d68a",
            "c1f1c82c4bca44f080ae174899ff73c3"
          ]
        },
        "id": "onqK4ieFQtgB",
        "outputId": "91199de1-0c0b-4014-fa5c-140d14a4dc3f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RAG] Загружено 3 документов из expert_knowledge.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e18cc1f759d44014b81a17b273c3f589"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9fe29d3a306495ca050a9d3dcf35812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c985b5f1f5f43a99ad5ed9f0f10da81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de3e4b19474c422d867dc2de2f7c9a66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/697 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dc9ba726c98495eb6e77ef91b6c1dfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62cd67d0fbab464daf437299d09a2e95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51862d7cfb72452eb4373849fea95bf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77410f268fc8444d91b9828e0786dd09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b3622a70749444c9e828d4c34d683dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/963 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8a6226bdbe5449c8c5039f211fa7516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19acb04f278f471c8255869e76d04d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/971 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4491a0768124a80b428132b0039bd99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05740f17a95d45a88421c801c67ef580"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6724ae49bef14e6198aa9e93063fade8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "667a8d4474194d0fae1993b67f83d94f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e240c6bc1ee4179adc928eb01adb047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a4492b2601f42048a38312efecd8c16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04a0379e92b2486283e41c287726e315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89fc410b66014018abb0ad424e3afe52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RAG] Эксперт: создано 6 чанков\n",
            "[RAG] Загружено 3 документов из manager_knowledge.csv\n",
            "[RAG] Менеджер: создано 6 чанков\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ИИ-агенты\n",
        "--------"
      ],
      "metadata": {
        "id": "N3lWcnQKSF09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InterviewState(TypedDict):\n",
        "    \"\"\"Состояние системы интервью\"\"\"\n",
        "    # История сообщений для контекста\n",
        "    messages: Annotated[List[Any], operator.add]\n",
        "\n",
        "    # Информация о кандидатате\n",
        "    candidate_info: Dict[str, str]\n",
        "\n",
        "    # Мысли агентов\n",
        "    expert_thoughts: str\n",
        "    manager_thoughts: str\n",
        "    interviewer_thoughts: str\n",
        "\n",
        "    # Лог интервью\n",
        "    interview_log: List[Dict[str, Any]]\n",
        "\n",
        "    # Флаги управления\n",
        "    is_interview_active: bool\n",
        "    current_turn: int\n",
        "\n",
        "\n",
        "\n",
        "def initialize_interview(candidate_info: Dict[str, str]) -> InterviewState:\n",
        "    initial_state = InterviewState(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"Вы начинаете техническое интервью с кандидатом.\n",
        "                Должность: {candidate_info['position']}\n",
        "                Уровень: {candidate_info['grade']}\n",
        "                Опыт: {candidate_info['experience']}\n",
        "\n",
        "                Ваша цель: провести глубокое техническое интервью,\n",
        "                оценить навыки кандидата и дать конструктивный фидбэк.\"\"\"}\n",
        "        ],\n",
        "        candidate_info=candidate_info,\n",
        "        expert_thoughts=\"\",\n",
        "        manager_thoughts=\"\",\n",
        "        interviewer_thoughts=\"\",\n",
        "        interview_log=[],\n",
        "        is_interview_active=True,\n",
        "        current_turn=1\n",
        "    )\n",
        "\n",
        "    print(f\"Кандидат: {candidate_info['name']}\")\n",
        "    print(f\"Позиция: {candidate_info['position']} {candidate_info['grade']}\")\n",
        "    print(f\"Опыт: {candidate_info['experience']}\")\n",
        "\n",
        "    return initial_state\n",
        "\n",
        "\n",
        "\n",
        "def expert_node(state: InterviewState) -> InterviewState:\n",
        "    \"\"\"Узел Эксперта: анализирует технические ответы кандидата\"\"\"\n",
        "\n",
        "    # Получаем последнее сообщение кандидата\n",
        "    last_human_message = None\n",
        "    for msg in reversed(state['messages']):\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            last_human_message = msg.get(\"content\")\n",
        "            break\n",
        "\n",
        "    if not last_human_message:\n",
        "        return state\n",
        "\n",
        "    expert_prompt = f\"\"\"\n",
        "    Ты - технический эксперт на интервью для позиции {state['candidate_info']['position']}.\n",
        "\n",
        "    ИНФОРМАЦИЯ О КАНДИДАТЕ:\n",
        "    Уровень: {state['candidate_info']['grade']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    ИСТОРИЯ ДИАЛОГА (последние 3 сообщения):\n",
        "    {_get_recent_messages(state['messages'])}\n",
        "\n",
        "    ПОСЛЕДНИЙ ОТВЕТ КАНДИДАТА:\n",
        "    \"{last_human_message}\"\n",
        "\n",
        "    ТВОЯ ЗАДАЧА:\n",
        "    Проанализируй техническую корректность ответа\n",
        "    Выяви пробелы в знаниях или неясности\n",
        "    Определи, правильно ли кандидат понимает концепции\n",
        "    Проверь на наличие галлюцинаций или ложных фактов\n",
        "    Предложи направление для следующих вопросов\n",
        "    Если пользователь задает ответ по теме или около нее, то ответь на него вежливо\n",
        "\n",
        "\n",
        "    ФОРМАТ ОТВЕТА:\n",
        "    Технический анализ: [анализ корректности ответа]\n",
        "    Пробелы/Ошибки: [выявленные проблемы]\n",
        "    Рекомендации для интервьюера: [конкретные предложения по следующим вопросам]\n",
        "    Уровень сложности: [оцени, нужно ли упростить или усложнить вопросы]\n",
        "    ответ на вопрос пользователя: [если есть вопрос иначе оставб пустым]\n",
        "\n",
        "    Твои мысли (пиши на русском, будь конкретным):\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": expert_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "    expert_analysis = response.choices[0].message.content\n",
        "\n",
        "    print(f\"\\n[ЭКСПЕРТ] Мысли:\\n{expert_analysis}\")\n",
        "\n",
        "    return {\n",
        "        \"expert_thoughts\": expert_analysis,\n",
        "        \"current_turn\": state['current_turn']\n",
        "    }\n",
        "\n",
        "def manager_node(state: InterviewState) -> InterviewState:\n",
        "    \"\"\"Узел Менеджера: стратегическое управление интервью\"\"\"\n",
        "\n",
        "\n",
        "    manager_prompt = f\"\"\"\n",
        "    Ты - менеджер по найму, управляешь ходом технического интервью.\n",
        "\n",
        "    ЦЕЛЬ ИНТЕРВЬЮ: Оценить кандидата на позицию {state['candidate_info']['position']} ({state['candidate_info']['grade']})\n",
        "\n",
        "    ИНФОРМАЦИЯ О КАНДИДАТЕ:\n",
        "    Имя: {state['candidate_info']['name']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    ТЕКУЩИЙ ХОД: {state['current_turn']} из 10\n",
        "\n",
        "    АНАЛИЗ ЭКСПЕРТА:\n",
        "    {state['expert_thoughts']}\n",
        "\n",
        "    ИСТОРИЯ ДИАЛОГА:\n",
        "    {_get_interview_summary(state['messages'])}\n",
        "\n",
        "    ТВОЯ ЗАДАЧА:\n",
        "    Оценить общий прогресс интервью\n",
        "    Решить, нужно ли сменить тему или углубиться в текущую\n",
        "    Оценить soft skills кандидата (ясность изложения, честность, вовлеченность)\n",
        "    Дать стратегические указания интервьюеру\n",
        "    Если пользователь задает ответ по теме или около нее, то ответь на него вежливо\n",
        "\n",
        "    ВАЖНО: Интервью должно продолжаться минимум 7 вопросов, чтобы полноценно оценить кандидата.\n",
        "    Завершать интервью можно только после 8-10 вопросов, если есть четкое понимание о несоответствии кандидата.\n",
        "\n",
        "    КРИТЕРИИ ОЦЕНКИ:\n",
        "    Технические знания (по анализу эксперта)\n",
        "    Коммуникационные навыки\n",
        "    Соответствие заявленному уровню\n",
        "\n",
        "    Твои мысли и решения (пиши на русском):\n",
        "    Общая оценка прогресса:\n",
        "    Решение по направлению:\n",
        "    Оценка soft skills:\n",
        "    Стратегия для интервьюера:\n",
        "    Рекомендация по продолжению (продолжить/завершить):\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": manager_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "    manager_analysis = response.choices[0].message.content\n",
        "\n",
        "    # Проверяем, не пора ли завершить интервью\n",
        "    should_end = _check_interview_end(manager_analysis, state['current_turn'])\n",
        "\n",
        "    print(f\"\\n[МЕНЕДЖЕР] Мысли:\\n{manager_analysis}\")\n",
        "    if should_end and state['current_turn'] >= 8:\n",
        "        print(f\"[МЕНЕДЖЕР] Решение: завершить интервью после {state['current_turn']} вопросов\")\n",
        "    elif state['current_turn'] >= 10:\n",
        "        print(\"[МЕНЕДЖЕР] Достигнут лимит в 10 вопросов\")\n",
        "\n",
        "    return {\n",
        "        \"manager_thoughts\": manager_analysis,\n",
        "        \"is_interview_active\": not should_end,\n",
        "        \"current_turn\": state['current_turn']\n",
        "    }\n",
        "\n",
        "def interviewer_node(state: InterviewState) -> InterviewState:\n",
        "    \"\"\"Узел Интервьюера: общение с кандидатом\"\"\"\n",
        "\n",
        "    last_human_message = None\n",
        "    for msg in reversed(state['messages']):\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            last_human_message = msg.get(\"content\")\n",
        "            break\n",
        "\n",
        "    interviewer_prompt = f\"\"\"\n",
        "    Ты - технический интервьюер. Ты общаешься напрямую с кандидатом.\n",
        "\n",
        "    КАНДИДАТ:\n",
        "    Имя: {state['candidate_info']['name']}\n",
        "    Позиция: {state['candidate_info']['position']} {state['candidate_info']['grade']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    {f'ПОСЛЕДНИЙ ОТВЕТ КАНДИДАТА: \"{last_human_message}\"' if last_human_message else 'НАЧАЛО ИНТЕРВЬЮ'}\n",
        "\n",
        "    РЕКОМЕНДАЦИИ ЭКСПЕРТА:\n",
        "    {state['expert_thoughts']}\n",
        "\n",
        "    СТРАТЕГИЯ МЕНЕДЖЕРА:\n",
        "    {state['manager_thoughts']}\n",
        "\n",
        "    ИСТОРИЯ ДИАЛОГА (последние 3 сообщения):\n",
        "    {_get_recent_messages(state['messages'], count=3)}\n",
        "\n",
        "    ИНСТРУКЦИИ:\n",
        "    Задай следующий технический вопрос, основанный на рекомендациях эксперта\n",
        "    Учитывай стратегию менеджера\n",
        "    Адаптируй сложность под уровень кандидата\n",
        "    Будь профессиональным, но дружелюбным\n",
        "    Если кандидат пытается сменить тему - вежливо верни к интервью\n",
        "    Если кандидат дает ложные факты - тактично поправь\n",
        "    Если кандидат задает уточняющий вопрос по заданию или по работе, ответь на него, и попытайся продолжить диалог с той же темой\n",
        "    Задавай вопросы на разные темы и теорию, а не концентрируйся на чем-то одном, при этом, при повышении сложности углубляйся в тему\n",
        "\n",
        "    ТВОЙ ВОПРОС/РЕПЛИКА КАНДИДАТУ (только вопрос, без внутренних мыслей):\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": interviewer_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "    interviewer_message = response.choices[0].message.content\n",
        "\n",
        "    new_message = {\"role\": \"assistant\", \"content\": interviewer_message}\n",
        "\n",
        "\n",
        "    log_entry = {\n",
        "        \"turn_id\": state['current_turn'],\n",
        "        \"user_message\": last_human_message if last_human_message else \"[НАЧАЛО ИНТЕРВЬЮ]\",\n",
        "        \"agent_visible_message\": interviewer_message,\n",
        "        \"internal_thoughts\": {\n",
        "            \"expert\": state['expert_thoughts'],\n",
        "            \"manager\": state['manager_thoughts'],\n",
        "            \"interviewer\": interviewer_prompt\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n[ИНТЕРВЬЮЕР] Вопрос ({state['current_turn']}):\")\n",
        "    print(f\"{interviewer_message}\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": [new_message],\n",
        "        \"interviewer_thoughts\": interviewer_prompt,\n",
        "        \"interview_log\": state['interview_log'] + [log_entry],\n",
        "        \"current_turn\": state['current_turn'] + 1\n",
        "    }"
      ],
      "metadata": {
        "id": "8R7k2DeASLEi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ИИ-агенты с инструментами\n",
        "--------------"
      ],
      "metadata": {
        "id": "eM4jjsOWSp8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@with_tools\n",
        "def expert_node_with_tools(state: InterviewState) -> InterviewState:\n",
        "    \"\"\"Узел Эксперта с RAG и интернет-поиском\"\"\"\n",
        "\n",
        "    # Получаем последнее сообщение кандидата\n",
        "    last_human_message = None\n",
        "    for msg in reversed(state['messages']):\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            last_human_message = msg.get(\"content\")\n",
        "            break\n",
        "\n",
        "    if not last_human_message:\n",
        "        return state\n",
        "\n",
        "    # Используем RAG для поиска релевантной информации\n",
        "    rag_context = \"\"\n",
        "    if rag_system.expert_rag:\n",
        "        rag_results = rag_system.search_expert_rag(last_human_message, k=2)\n",
        "        if rag_results:\n",
        "            rag_context = \"\\n\".join([f\"[RAG] {result}\" for result in rag_results])\n",
        "\n",
        "    # Используем интернет-поиск\n",
        "    internet_context = \"\"\n",
        "    try:\n",
        "        internet_results = internet_search.search_web(last_human_message, num_results=2)\n",
        "        if internet_results:\n",
        "            internet_context = f\"\\n[ИНТЕРНЕТ-ПОИСК]:\\n{internet_results}\"\n",
        "    except Exception as e:\n",
        "        internet_context = f\"\\n[ИНТЕРНЕТ-ПОИСК]: Ошибка - {str(e)}\"\n",
        "\n",
        "    expert_prompt = f\"\"\"\n",
        "    Ты - технический эксперт на интервью для позиции {state['candidate_info']['position']}.\n",
        "\n",
        "    ИНФОРМАЦИЯ О КАНДИДАТЕ:\n",
        "    Уровень: {state['candidate_info']['grade']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    РЕЛЕВАНТНАЯ ИНФОРМАЦИЯ ИЗ БАЗЫ ЗНАНИЙ:\n",
        "    {rag_context}\n",
        "\n",
        "    АКТУАЛЬНАЯ ИНФОРМАЦИЯ ИЗ ИНТЕРНЕТА:\n",
        "    {internet_context}\n",
        "\n",
        "    ИСТОРИЯ ДИАЛОГА (последние 3 сообщения):\n",
        "    {_get_recent_messages(state['messages'])}\n",
        "\n",
        "    ПОСЛЕДНИЙ ОТВЕТ КАНДИДАТА:\n",
        "    \"{last_human_message}\"\n",
        "\n",
        "    ТВОЯ ЗАДАЧА:\n",
        "    Проанализируй техническую корректность ответа\n",
        "    Выяви пробелы в знаниях или неясности\n",
        "    Определи, правильно ли кандидат понимает концепции\n",
        "    Проверь на наличие галлюцинаций или ложных фактов\n",
        "    Предложи направление для следующих вопросов. Используй\n",
        "    информацию из базы знаний и интернета для более точного анализа\n",
        "    Проверь, актуальна ли информация кандидата с учетом современных трендов\n",
        "    Если пользователь задает ответ по теме или около нее, то ответь на него вежливо\n",
        "\n",
        "    ФОРМАТ ОТВЕТА:\n",
        "    Технический анализ: [анализ корректности ответа]\n",
        "    Пробелы/Ошибки: [выявленные проблемы]\n",
        "    Рекомендации для интервьюера: [конкретные предложения по следующим вопросам]\n",
        "    Уровень сложности: [оцени, нужно ли упростить или усложнить вопросы]\n",
        "    Актуальность: [соответствует ли современным стандартам]\n",
        "\n",
        "    Твои мысли (пиши на русском, будь конкретным):\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": expert_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "    expert_analysis = response.choices[0].message.content\n",
        "\n",
        "    print(f\"\\n[ЭКСПЕРТ С ИНСТРУМЕНТАМИ] Мысли:\\n{expert_analysis}\")\n",
        "    if rag_context:\n",
        "        print(f\"[ЭКСПЕРТ] Использовал RAG: {len(rag_context)} символов контекста\")\n",
        "    if internet_context:\n",
        "        print(f\"[ЭКСПЕРТ] Использовал интернет-поиск\")\n",
        "\n",
        "    return {\n",
        "        \"expert_thoughts\": expert_analysis,\n",
        "        \"current_turn\": state['current_turn']\n",
        "    }\n",
        "\n",
        "@with_tools\n",
        "def manager_node_with_tools(state: InterviewState) -> InterviewState:\n",
        "    \"\"\"Узел Менеджера только с RAG\"\"\"\n",
        "\n",
        "    # Используем RAG для менеджера (поиск в HR/менеджерской базе знаний)\n",
        "    rag_context = \"\"\n",
        "    if rag_system.manager_rag:\n",
        "        query = f\"{state['candidate_info']['position']} {state['candidate_info']['grade']} найм\"\n",
        "        rag_results = rag_system.search_manager_rag(query, k=2)\n",
        "        if rag_results:\n",
        "            rag_context = \"\\n\".join([f\"[RAG Менеджер] {result}\" for result in rag_results])\n",
        "\n",
        "    manager_prompt = f\"\"\"\n",
        "    Ты - менеджер по найму, управляешь ходом технического интервью.\n",
        "\n",
        "    ЦЕЛЬ ИНТЕРВЬЮ: Оценить кандидата на позицию {state['candidate_info']['position']} ({state['candidate_info']['grade']})\n",
        "\n",
        "    ИНФОРМАЦИЯ О КАНДИДАТЕ:\n",
        "    Имя: {state['candidate_info']['name']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    РЕЛЕВАНТНАЯ ИНФОРМАЦИЯ ДЛЯ МЕНЕДЖЕРА:\n",
        "    {rag_context}\n",
        "\n",
        "    ТЕКУЩИЙ ХОД: {state['current_turn']} из 10\n",
        "\n",
        "    АНАЛИЗ ЭКСПЕРТА:\n",
        "    {state['expert_thoughts']}\n",
        "\n",
        "    ИСТОРИЯ ДИАЛОГА:\n",
        "    {_get_interview_summary(state['messages'])}\n",
        "\n",
        "    ТВОЯ ЗАДАЧА:\n",
        "    Оценить общий прогресс интервью\n",
        "    Решить, нужно ли сменить тему или углубиться в текущую\n",
        "    Оценить soft skills кандидата (ясность изложения, честность, вовлеченность)\n",
        "    Дать стратегические указания интервьюеру\n",
        "    Используй информацию из базы знаний менеджера для принятия решений\n",
        "    Учитывай рыночные стандарты и лучшие практики найма\n",
        "    Если пользователь задает ответ по теме или около нее, то ответь на него вежливо\n",
        "\n",
        "    ВАЖНО: Интервью должно продолжаться минимум 7 вопросов, чтобы полноценно оценить кандидата.\n",
        "    Завершать интервью можно только после 8-10 вопросов, если есть четкое понимание о несоответствии кандидата.\n",
        "\n",
        "    КРИТЕРИИ ОЦЕНКИ:\n",
        "    Технические знания (по анализу эксперта)\n",
        "    Коммуникационные навыки\n",
        "    Соответствие заявленному уровню\n",
        "\n",
        "    Твои мысли и решения (пиши на русском):\n",
        "    Общая оценка прогресса:\n",
        "    Решение по направлению:\n",
        "    Оценка soft skills:\n",
        "    Стратегия для интервьюера:\n",
        "    Рекомендация по продолжению (продолжить/завершить):\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": manager_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "    manager_analysis = response.choices[0].message.content\n",
        "\n",
        "    should_end = _check_interview_end(manager_analysis, state['current_turn'])\n",
        "\n",
        "    print(f\"\\n[МЕНЕДЖЕР С RAG] Мысли:\\n{manager_analysis}\")\n",
        "    if rag_context:\n",
        "        print(f\"[МЕНЕДЖЕР] Использовал RAG\")\n",
        "\n",
        "    return {\n",
        "        \"manager_thoughts\": manager_analysis,\n",
        "        \"is_interview_active\": not should_end,\n",
        "        \"current_turn\": state['current_turn']\n",
        "    }"
      ],
      "metadata": {
        "id": "Rqc8cK6QSwn6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вспомагательные функции, фидбэк\n",
        "--------"
      ],
      "metadata": {
        "id": "uxYU8k-nUgi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_recent_messages(messages: List, count: int = 3) -> str:\n",
        "    \"\"\"Получает последние сообщения из истории\"\"\"\n",
        "    recent = []\n",
        "    for msg in messages[-count*2:]:\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            recent.append(f\"Кандидат: {msg.get('content')}\")\n",
        "        elif msg.get(\"role\") == \"assistant\":\n",
        "            recent.append(f\"Интервьюер: {msg.get('content')}\")\n",
        "\n",
        "    return \"\\n\".join(recent[-count:]) if recent else \"История пуста\"\n",
        "\n",
        "def _get_interview_summary(messages: List) -> str:\n",
        "    \"\"\"Получает краткое содержание интервью\"\"\"\n",
        "    summary = []\n",
        "    for i, msg in enumerate(messages):\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            summary.append(f\"{i+1}. Кандидат: {msg.get('content', '')}\")\n",
        "        elif msg.get(\"role\") == \"assistant\":\n",
        "            summary.append(f\"{i+1}. Интервьюер: {msg.get('content', '')}\")\n",
        "\n",
        "    return \"\\n\".join(summary[-10:]) if summary else \"Диалог еще не начался\"\n",
        "\n",
        "def _check_interview_end(manager_thoughts: str, current_turn: int) -> bool:\n",
        "    \"\"\"Проверяет, пора ли завершить интервью\"\"\"\n",
        "    # Завершаем после 10 ходов\n",
        "    if current_turn >= 10:\n",
        "        return True\n",
        "\n",
        "    if current_turn < 8:\n",
        "        return False\n",
        "\n",
        "    end_phrases = [\n",
        "        \"завершить интервью\",\n",
        "        \"достаточно вопросов\",\n",
        "        \"хватит\",\n",
        "        \"закончить интервью\",\n",
        "        \"стоп интервью\",\n",
        "        \"кандидат не подходит\",\n",
        "        \"отклонить кандидата\",\n",
        "        \"рекомендую завершить\"\n",
        "    ]\n",
        "\n",
        "    manager_lower = manager_thoughts.lower()\n",
        "\n",
        "    # Проверяем наличие фраз о завершении\n",
        "    has_end_phrase = any(phrase in manager_lower for phrase in end_phrases)\n",
        "\n",
        "    # Для 5-7 вопросов: завершаем только при очень явном указании и если кандидат явно не подходит\n",
        "    if current_turn < 8:\n",
        "        strong_end_phrases = [\n",
        "            \"кандидат не подходит\",\n",
        "            \"отклонить кандидата\",\n",
        "            \"явное несоответствие\",\n",
        "            \"советую завершить немедленно\"\n",
        "        ]\n",
        "        return any(phrase in manager_lower for phrase in strong_end_phrases)\n",
        "\n",
        "    # После 8 вопросов можно завершать по рекомендации менеджера\n",
        "    return has_end_phrase\n",
        "\n",
        "def generate_final_feedback(state: InterviewState) -> Dict[str, Any]:\n",
        "\n",
        "    expert_thoughts_all = []\n",
        "    manager_thoughts_all = []\n",
        "\n",
        "    for log_entry in state['interview_log']:\n",
        "        if 'internal_thoughts' in log_entry:\n",
        "            expert_thoughts_all.append(log_entry['internal_thoughts'].get('expert', ''))\n",
        "            manager_thoughts_all.append(log_entry['internal_thoughts'].get('manager', ''))\n",
        "\n",
        "    expert_summary = \"\\n\".join([thought for thought in expert_thoughts_all if thought])\n",
        "    manager_summary = \"\\n\".join([thought for thought in manager_thoughts_all if thought])\n",
        "\n",
        "    if not expert_summary:\n",
        "        expert_summary = state['expert_thoughts']\n",
        "    if not manager_summary:\n",
        "        manager_summary = state['manager_thoughts']\n",
        "\n",
        "    feedback_prompt = f\"\"\"\n",
        "    На основе проведенного интервью сгенерируй структурированный фидбэк.\n",
        "\n",
        "    ИНФОРМАЦИЯ О КАНДИДАТЕ:\n",
        "    Имя: {state['candidate_info']['name']}\n",
        "    Позиция: {state['candidate_info']['position']}\n",
        "    Уровень: {state['candidate_info']['grade']}\n",
        "    Опыт: {state['candidate_info']['experience']}\n",
        "\n",
        "    ИСТОРИЯ ИНТЕРВЬЮ (все сообщения):\n",
        "    {_get_interview_summary(state['messages'])}\n",
        "\n",
        "    АНАЛИЗ ЭКСПЕРТА (ключевые моменты):\n",
        "    {expert_summary}\n",
        "\n",
        "    АНАЛИЗ МЕНЕДЖЕРА (ключевые моменты):\n",
        "    {manager_summary}\n",
        "\n",
        "    КОЛИЧЕСТВО ВОПРОСОВ: {state['current_turn'] - 1}\n",
        "\n",
        "    СГЕНЕРИРУЙ ФИДБЭК В СЛЕДУЮЩЕЙ СТРУКТУРЕ:\n",
        "\n",
        "    Вердикт (Decision)\n",
        "    Grade: Junior/Middle/Senior (оценка уровня на основе ответов)\n",
        "    iring Recommendation: Strong Hire / Hire / Borderline / No Hire\n",
        "    Confidence Score: 0-100% (уверенность в оценке)\n",
        "\n",
        "    Анализ Hard Skills (Technical Review)\n",
        "    Confirmed Skills: [темы, где кандидат дал точные ответы]\n",
        "    Knowledge Gaps: [темы с ошибками или \"не знаю\"]\n",
        "    Правильные ответы на вопросы с ошибками: [исправления]\n",
        "\n",
        "    Анализ Soft Skills & Communication\n",
        "    Clarity: [оценка ясности изложения]\n",
        "    Honesty: [оценка честности]\n",
        "    Engagement: [оценка вовлеченности]\n",
        "\n",
        "    Персональный Roadmap (Next Steps)\n",
        "    Рекомендации по изучению: [конкретные темы]\n",
        "    Ресурсы: [ссылки или названия материалов]\n",
        "    Советы по подготовке: [практические советы]\n",
        "\n",
        "    Фидбэк должен быть на русском, конкретным и полезным для кандидата.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[{\"role\": \"user\", \"content\": feedback_prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=None,\n",
        "    )\n",
        "\n",
        "    feedback_text = response.choices[0].message.content\n",
        "\n",
        "    formatted_turns = []\n",
        "    for turn in state['interview_log']:\n",
        "        internal_thoughts_dict = turn.get('internal_thoughts', {})\n",
        "\n",
        "        expert_part = internal_thoughts_dict.get('expert', '')\n",
        "        manager_part = internal_thoughts_dict.get('manager', '')\n",
        "        interviewer_part = internal_thoughts_dict.get('interviewer', '')\n",
        "\n",
        "        internal_thoughts_str = \"\"\n",
        "        if expert_part:\n",
        "            expert_short = \". \".join(expert_part.split(\". \")) + \".\"\n",
        "            internal_thoughts_str += f\"[Observer]: {expert_short} \"\n",
        "        if manager_part:\n",
        "          manager_short = \". \".join(manager_part.split(\". \")) + \".\"\n",
        "          internal_thoughts_str += f\"[manager]: {manager_short} \"\n",
        "        if interviewer_part:\n",
        "            interviewer_short = \". \".join(interviewer_part.split(\". \")) + \".\"\n",
        "            internal_thoughts_str += f\"[Interviewer]: {interviewer_short}\"\n",
        "\n",
        "        formatted_turn = {\n",
        "                \"turn_id\": turn[\"turn_id\"],\n",
        "                \"agent_visible_message\": turn[\"agent_visible_message\"],\n",
        "                \"user_message\": turn[\"user_message\"],\n",
        "                \"internal_thoughts\": internal_thoughts_str.strip()\n",
        "            }\n",
        "        formatted_turns.append(formatted_turn)\n",
        "\n",
        "    return {\n",
        "        \"participant_name\": \"Алешин Кирилл Александрович\",\n",
        "        \"turns\": formatted_turns,\n",
        "        \"final_feedback\": feedback_text\n",
        "    }\n",
        "\n",
        "# граф модели с помощью Langraph\n",
        "def create_interview_graph() -> StateGraph:\n",
        "    \"\"\"Создание графа интервью\"\"\"\n",
        "\n",
        "    graph = StateGraph(InterviewState)\n",
        "\n",
        "    graph.add_node(\"expert\", expert_node)\n",
        "    graph.add_node(\"manager\", manager_node)\n",
        "    graph.add_node(\"interviewer\", interviewer_node)\n",
        "\n",
        "    graph.set_entry_point(\"expert\")\n",
        "    graph.add_edge(\"expert\", \"manager\")\n",
        "    graph.add_edge(\"manager\", \"interviewer\")\n",
        "    graph.add_edge(\"interviewer\", END)\n",
        "\n",
        "    return graph.compile()\n",
        "\n",
        "def create_interview_graph_with_tools() -> StateGraph:\n",
        "    \"\"\"Создание графа интервью с инструментами\"\"\"\n",
        "\n",
        "    graph = StateGraph(InterviewState)\n",
        "\n",
        "\n",
        "    graph.add_node(\"expert\", expert_node_with_tools)\n",
        "    graph.add_node(\"manager\", manager_node_with_tools)\n",
        "    graph.add_node(\"interviewer\", interviewer_node)\n",
        "\n",
        "    graph.set_entry_point(\"expert\")\n",
        "    graph.add_edge(\"expert\", \"manager\")\n",
        "    graph.add_edge(\"manager\", \"interviewer\")\n",
        "    graph.add_edge(\"interviewer\", END)\n",
        "\n",
        "    return graph.compile()\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"MULTI-AGENT INTERVIEW COACH SYSTEM\")\n",
        "    print(\"1. Базовая версия\")\n",
        "    print(\"2. Версия с RAG и интернет-поиском\")\n",
        "\n",
        "    choice = input(\"Выберите версию (1 или 2): \").strip()\n",
        "\n",
        "    # Инициализация\n",
        "    print(\"\\nИнициализация:\")\n",
        "    candidate_info = {\n",
        "        \"name\": input(\"Имя кандидата: \").strip(),\n",
        "        \"position\": input(\"Позиция (например, Backend Developer): \").strip(),\n",
        "        \"grade\": input(\"Грейд (Junior/Middle/Senior): \").strip(),\n",
        "        \"experience\": input(\"Опыт и навыки: \").strip(),\n",
        "    }\n",
        "\n",
        "    state = initialize_interview(candidate_info)\n",
        "\n",
        "    # Выбираем граф в зависимости от выбора\n",
        "    if choice == \"2\":\n",
        "        print(\"\\n[ИСПОЛЬЗУЕТСЯ ВЕРСИЯ С ИНСТРУМЕНТАМИ]\")\n",
        "        graph = create_interview_graph_with_tools()\n",
        "    else:\n",
        "        graph = create_interview_graph()\n",
        "\n",
        "    #Основной цикл\n",
        "    print(\"(введите 'стоп' для завершения или 'фидбэк' для получения отчета)\")\n",
        "\n",
        "    while state['is_interview_active'] and state['current_turn'] <= 10:\n",
        "        try:\n",
        "            user_input = input(f\"\\nКандидат (вопрос {state['current_turn']}): \").strip()\n",
        "\n",
        "            if user_input.lower() in ['стоп', 'stop', 'завершить']:\n",
        "                state['is_interview_active'] = False\n",
        "                break\n",
        "\n",
        "            if user_input.lower() in ['фидбэк', 'feedback', 'отчет']:\n",
        "                state['is_interview_active'] = False\n",
        "                break\n",
        "\n",
        "\n",
        "            state['messages'].append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            # один графовый цикл\n",
        "            state.update(graph.invoke(state))\n",
        "\n",
        "            if not state['is_interview_active']:\n",
        "                print(f\"\\n Интервью завершено менеджером\")\n",
        "                break\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            state['is_interview_active'] = False\n",
        "            break\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    # фидбэк\n",
        "    final_result = generate_final_feedback(state)\n",
        "\n",
        "    output_filename = f\"interview_log_{candidate_info['name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(final_result, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n фидбэк сохранен в файл: {output_filename}\")\n",
        "    feedback_text = final_result['final_feedback']\n",
        "\n",
        "    # Проверяем, содержит ли фидбэк разделы\n",
        "    sections = [\"Вердикт\", \"Анализ Hard Skills\", \"Анализ Soft Skills\", \"Персональный Roadmap\"]\n",
        "\n",
        "    for section in sections:\n",
        "        if section in feedback_text:\n",
        "            start = feedback_text.find(section)\n",
        "            # Ищем конец раздела - следующий раздел или конец текста\n",
        "            next_section_start = len(feedback_text)\n",
        "            for next_section in sections:\n",
        "                if next_section in feedback_text[start+1:]:\n",
        "                    pos = feedback_text.find(next_section, start+1)\n",
        "                    if pos < next_section_start and pos > start:\n",
        "                        next_section_start = pos\n",
        "\n",
        "            section_text = feedback_text[start:next_section_start].strip()\n",
        "            print(section_text)\n",
        "        else:\n",
        "            # Если раздел не найден, пытаемся найти альтернативные варианты\n",
        "            alt_patterns = [\n",
        "                f\"{section} (\",\n",
        "                f\"{section}:\",\n",
        "                f\"**{section}**\",\n",
        "                f\"{section.split('(')[0]}\"\n",
        "            ]\n",
        "            for pattern in alt_patterns:\n",
        "                if pattern in feedback_text:\n",
        "                    start = feedback_text.find(pattern)\n",
        "                    end = feedback_text.find(\"\\n\\n\", start)\n",
        "                    if end == -1:\n",
        "                        end = len(feedback_text)\n",
        "                    section_text = feedback_text[start:end]\n",
        "                    print(section_text)\n",
        "                    break\n",
        "\n",
        "    print(f\"\\nИнтервью завершено.\")\n",
        "    print(f\"логи: {output_filename}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ac8tz5bIUft3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main\n",
        "---"
      ],
      "metadata": {
        "id": "KnJuJg3WUzTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#пример\n",
        "# Имя: Алекс\n",
        "#     Позиция: Backend Developer\n",
        "#     Грейд: Junior\n",
        "#     Опыт: Пет-проекты на Django, немного SQL.\n",
        "# Привет. Я Алекс, претендую на позицию Junior Backend Developer. Знаю Python, SQL и Git.\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_twbWiN_U8Yu",
        "outputId": "dc29ace7-64f6-4430-dedb-ce429b2400ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MULTI-AGENT INTERVIEW COACH SYSTEM\n",
            "1. Базовая версия\n",
            "2. Версия с RAG и интернет-поиском\n",
            "Выберите версию (1 или 2): 1\n",
            "\n",
            "Инициализация:\n",
            "Имя кандидата: Олег\n",
            "Позиция (например, Backend Developer): Java Developer\n",
            "Грейд (Junior/Middle/Senior): Junior\n",
            "Опыт и навыки: Java Developer\n",
            "Кандидат: Олег\n",
            "Позиция: Java Developer Junior\n",
            "Опыт: Java Developer\n",
            "(введите 'стоп' для завершения или 'фидбэк' для получения отчета)\n",
            "\n",
            "Кандидат (вопрос 1): Привет! я Олег. Претендую на Junior Java Developer. Готов начать.\n",
            "\n",
            "[ЭКСПЕРТ] Мысли:\n",
            "**Технический анализ:**\n",
            "Ответ кандидата (\"Привет! я Олег. Претендую на Junior Java Developer. Готов начать.\") не содержит технической информации, поэтому оценить корректность знаний по Java невозможно. Это приветствие и заявка на участие в интервью, а не ответ на технический вопрос.\n",
            "\n",
            "**Пробелы/Ошибки:**\n",
            "1. Отсутствие демонстрации базовых знаний Java (например, ключевые концепции ООП, коллекции, работа с потоками и т.д.).\n",
            "2. Нет упоминания опыта работы с фреймворками (Spring, Hibernate) или инструментами (Maven/Gradle, Git), которые обычно ожидаются даже от Junior-разработчика.\n",
            "3. Неясно, понимает ли кандидат структуру собеседования (ожидает ли он вопросы или готов сразу рассказать о себе).\n",
            "\n",
            "**Рекомендации для интервьюера:**\n",
            "1. **Начать с базовых вопросов по Java:**\n",
            "   - Что такое инкапсуляция/наследование/полиморфизм? Приведи примеры.\n",
            "   - Чем отличается `ArrayList` от `LinkedList`? Когда какой использовать?\n",
            "   - Что такое `final` в Java и как оно применяется к классам, методам и переменным?\n",
            "2. **Проверить понимание ООП:**\n",
            "   - Попросить объяснить разницу между абстрактным классом и интерфейсом.\n",
            "   - Привести пример полиморфизма в коде.\n",
            "3. **Задать практические задачи:**\n",
            "   - Написать метод, который проверяет, является ли строка палиндромом.\n",
            "   - Объяснить, как работает сборщик мусора (Garbage Collector) в Java.\n",
            "4. **Уточнить опыт:**\n",
            "   - Какие проекты на Java ты реализовывал? Какие технологии использовал?\n",
            "   - Работал ли с базами данных (JDBC, JPA/Hibernate)?\n",
            "\n",
            "**Уровень сложности:**\n",
            "Начать с **базового уровня**, чтобы оценить фундаментальные знания. Если кандидат отвечает уверенно, можно постепенно усложнять вопросы (например, перейти к многопоточности или Spring).\n",
            "\n",
            "**Ответ на вопрос пользователя:**\n",
            "*\"Привет, Олег! Рад познакомиться. Давай начнем с небольшого разговора о твоем опыте. Расскажи, пожалуйста, с какими технологиями на Java ты работал и какие проекты реализовывал?\"*\n",
            "\n",
            "---\n",
            "**Твои мысли:**\n",
            "Кандидат пока не продемонстрировал технические знания, поэтому важно начать с простых вопросов, чтобы понять его уровень. Если ответы будут поверхностными, стоит уточнить, насколько глубоко он изучал Java (курсы, книги, практика). Если же он уверенно ответит на базовые вопросы, можно переходить к более сложным темам (например, многопоточность или Spring).\n",
            "\n",
            "[МЕНЕДЖЕР] Мысли:\n",
            "**Твои мысли и решения:**\n",
            "\n",
            "1. **Общая оценка прогресса:**\n",
            "   - Интервью находится на **начальной стадии (1/10)**, кандидат пока не продемонстрировал технические знания.\n",
            "   - Ответ Олега формальный, без конкретики — это сигнал к тому, что нужно **активно направлять диалог** и задавать наводящие вопросы, чтобы выявить реальный уровень.\n",
            "\n",
            "2. **Решение по направлению:**\n",
            "   - **Перейти к техническим вопросам базового уровня**, чтобы оценить фундаментальные знания Java.\n",
            "   - Если кандидат ответит уверенно, можно углубиться в темы (например, ООП, коллекции, многопоточность).\n",
            "   - Если ответы будут поверхностными, уточнить источники обучения (курсы, книги, пет-проекты) и перейти к практическим задачам.\n",
            "\n",
            "3. **Оценка soft skills:**\n",
            "   - **Ясность изложения:** Пока низкая — ответ односложный, без деталей.\n",
            "   - **Вовлеченность:** Кандидат готов начать, но не проявляет инициативы (например, не рассказывает о себе сам).\n",
            "   - **Честность:** Пока не оценивается — нужно больше данных.\n",
            "\n",
            "4. **Стратегия для интервьюера:**\n",
            "   - **Начать с вопросов по ООП** (например, \"Объясни, что такое полиморфизм, и приведи пример\").\n",
            "   - Если ответ будет слабым, перейти к **практическим задачам** (например, \"Напиши метод, который проверяет строку на палиндром\").\n",
            "   - Уточнить опыт работы с **фреймворками и инструментами** (Spring, Git, Maven).\n",
            "   - Следить за **логикой ответов** — если кандидат путается в базовых понятиях, это красный флаг для Junior-позиции.\n",
            "\n",
            "5. **Рекомендация по продолжению:**\n",
            "   - **Продолжить интервью**, так как пока рано делать выводы.\n",
            "   - Если после 3–4 технических вопросов кандидат не сможет ответить на базовом уровне, можно **вежливо завершить** собеседование с формулировкой: *\"Спасибо за участие, Олег. Мы рассмотрим твою кандидатуру и свяжемся с тобой в ближайшее время\"*.\n",
            "\n",
            "---\n",
            "\n",
            "**Следующий вопрос интервьюера:**\n",
            "*\"Отлично, Олег! Давай начнем с основ. Можешь объяснить, что такое полиморфизм в Java, и привести пример его использования в коде?\"*\n",
            "\n",
            "**Почему этот вопрос:**\n",
            "- Проверяет понимание **ключевой концепции ООП**.\n",
            "- Позволяет оценить **умение объяснять технические термины**.\n",
            "- Если кандидат ответит, можно перейти к **абстрактным классам/интерфейсам** или **коллекциям**. Если нет — задать более простой вопрос (например, \"Что такое инкапсуляция?\").\n",
            "\n",
            "**Дальнейшие шаги:**\n",
            "- Если ответ будет **уверенным**, перейти к вопросам о **коллекциях** или **исключениях**.\n",
            "- Если ответ будет **слабым**, уточнить: *\"А как ты изучал Java? Какие источники использовал?\"* и дать **практическую задачу** (например, реализовать простой класс с инкапсуляцией).\n",
            "\n",
            "[ИНТЕРВЬЮЕР] Вопрос (1):\n",
            "Отлично, Олег! Давай начнём с основ Java. Можешь объяснить, что такое полиморфизм, и привести пример его использования в коде?\n",
            "\n",
            "Кандидат (вопрос 2): Полиморфизм в Java — это возможность объектов одного типа вести себя по-разному в зависимости от конкретной реализации. Простыми словами, это способность метода выполнять разные действия на основе объекта, который его вызывает.  Чаще всего полиморфизм реализуется через переопределение методов и использование ссылок родительского класса. lass Animal {     void makeSound() {         System.out.println(\"Some sound\");     } }  class Dog extends Animal {     @Override     void makeSound() {         System.out.println(\"Woof!\");     } }  class Cat extends Animal {     @Override     void makeSound() {         System.out.println(\"Meow!\");     } }  public class Main {     public static void main(String[] args) {         Animal myAnimal = new Dog();         myAnimal.makeSound(); // Вывод: Woof!          myAnimal = new Cat();         myAnimal.makeSound(); // Вывод: Meow!     } }\n",
            "\n",
            "[ЭКСПЕРТ] Мысли:\n",
            "**Технический анализ:**\n",
            "Ответ кандидата технически корректен и демонстрирует понимание полиморфизма в Java. Приведенный пример с классами `Animal`, `Dog` и `Cat` правильно иллюстрирует:\n",
            "1. **Переопределение методов** (`@Override` у наследников).\n",
            "2. **Полиморфизм времени выполнения** (runtime polymorphism) через ссылку родительского класса (`Animal`), которая указывает на объекты разных типов (`Dog`, `Cat`).\n",
            "3. Корректное поведение метода `makeSound()` в зависимости от фактического типа объекта.\n",
            "\n",
            "Единственная опечатка — слово `lass` вместо `class` в определении `Animal`, но это явно случайная ошибка при наборе кода.\n",
            "\n",
            "---\n",
            "\n",
            "**Пробелы/Ошибки:**\n",
            "1. **Неполное объяснение типов полиморфизма**:\n",
            "   - Кандидат упомянул только **полиморфизм времени выполнения** (runtime polymorphism), но не коснулся **полиморфизма времени компиляции** (compile-time polymorphism), например, перегрузки методов (method overloading).\n",
            "   - Стоило уточнить, что полиморфизм в Java реализуется через:\n",
            "     - Наследование + переопределение методов (как в примере).\n",
            "     - Интерфейсы (например, реализация метода `run()` из `Runnable`).\n",
            "\n",
            "2. **Отсутствие упоминания ключевых терминов**:\n",
            "   - Не прозвучали термины **\"динамическое связывание\"** (dynamic binding) или **\"позднее связывание\"** (late binding), которые напрямую связаны с полиморфизмом времени выполнения.\n",
            "   - Не объяснена роль **виртуальных методов** (в Java все методы виртуальные по умолчанию, кроме `static`, `final` и `private`).\n",
            "\n",
            "3. **Ограниченность примера**:\n",
            "   - Пример хорош, но не показывает, как полиморфизм используется в реальных сценариях (например, коллекции объектов разных типов, но с общим интерфейсом).\n",
            "\n",
            "---\n",
            "\n",
            "**Рекомендации для интервьюера:**\n",
            "1. **Углубить понимание типов полиморфизма**:\n",
            "   - *\"Можешь привести пример полиморфизма времени компиляции (compile-time polymorphism) в Java?\"*\n",
            "   - *\"Как бы ты реализовал полиморфизм с использованием интерфейсов вместо наследования?\"*\n",
            "\n",
            "2. **Проверить знание механизмов работы**:\n",
            "   - *\"Почему в Java методы по умолчанию виртуальные? Как это связано с полиморфизмом?\"*\n",
            "   - *\"Что произойдет, если метод в родительском классе объявить как `final`? Как это повлияет на полиморфизм?\"*\n",
            "\n",
            "3. **Практическое применение**:\n",
            "   - *\"Представь, что у тебя есть список `List<Animal>`. Как ты реализуешь метод, который заставит всех животных издать звук?\"*\n",
            "   - *\"Как полиморфизм помогает в проектировании гибких и расширяемых систем?\"*\n",
            "\n",
            "4. **Связь с другими концепциями**:\n",
            "   - *\"Как полиморфизм связан с инкапсуляцией и абстракцией?\"*\n",
            "   - *\"Можно ли считать перегрузку операторов (например, `+` для строк) формой полиморфизма?\"* (Подсказка: в Java перегрузка операторов не поддерживается, кроме `+` для строк, но это хороший вопрос для обсуждения.)\n",
            "\n",
            "---\n",
            "\n",
            "**Уровень сложности:**\n",
            "- Текущий вопрос был **базовым** (ожидаемо для Junior), но ответ кандидата показал хорошее понимание.\n",
            "- Следующие вопросы можно **усложнить**, добавив:\n",
            "  - Практические сценарии (например, работа с коллекциями).\n",
            "  - Вопросы о внутренних механизмах (dynamic binding, таблицы виртуальных методов).\n",
            "  - Связь с другими ООП-концепциями.\n",
            "\n",
            "---\n",
            "\n",
            "**Ответ на вопрос пользователя:**\n",
            "*(В данном случае кандидат не задавал вопроса, поэтому поле оставляем пустым.)*\n",
            "\n",
            "---\n",
            "**Твои мысли:**\n",
            "Кандидат продемонстрировал **твердое понимание базового полиморфизма**, но есть пространство для углубления. Его ответ был структурированным и технически верным, что хорошо для Junior. Следующие вопросы стоит направить на:\n",
            "1. **Различие между compile-time и runtime полиморфизмом** (чтобы проверить глубину знаний).\n",
            "2. **Практическое применение** (например, работа с коллекциями или интерфейсами).\n",
            "3. **Внутренние механизмы** (как работает dynamic binding), чтобы отличить \"знаю как использовать\" от \"понимаю как это работает под капотом\".\n",
            "\n",
            "Если кандидат справится с этими вопросами, можно переходить к более сложным темам (например, SOLID, паттерны проектирования). Если нет — вернуться к основам ООП.\n",
            "\n",
            "[МЕНЕДЖЕР] Мысли:\n",
            "### **Анализ текущего состояния интервью**\n",
            "\n",
            "#### **1. Общая оценка прогресса (2/10)**\n",
            "- **Технические знания**: Кандидат продемонстрировал **хорошее понимание базового полиморфизма** (runtime polymorphism) и правильно привел пример с наследованием и переопределением методов. Однако есть пробелы:\n",
            "  - Не упомянул **compile-time polymorphism** (перегрузка методов).\n",
            "  - Не объяснил **механизмы работы** (dynamic binding, виртуальные методы).\n",
            "  - Пример ограничен и не показывает **практическое применение** (например, работа с коллекциями).\n",
            "- **Соответствие уровню Junior**: Ответ соответствует ожиданиям, но требует углубления.\n",
            "\n",
            "#### **2. Решение по направлению**\n",
            "- **Углубиться в текущую тему (полиморфизм)**, чтобы проверить:\n",
            "  - Понимание **разницы между compile-time и runtime полиморфизмом**.\n",
            "  - Знание **внутренних механизмов** (как работает dynamic binding).\n",
            "  - **Практическое применение** (например, работа с интерфейсами или коллекциями).\n",
            "- Если кандидат справится, можно перейти к **смежным темам** (инкапсуляция, абстракция, SOLID).\n",
            "\n",
            "#### **3. Оценка soft skills**\n",
            "✅ **Плюсы**:\n",
            "- **Ясность изложения**: Ответ структурирован, пример кода корректен (за исключением опечатки).\n",
            "- **Честность**: Не пытался \"выкрутиться\" или придумать несуществующие знания.\n",
            "- **Вовлеченность**: Готовность отвечать и приводить примеры.\n",
            "\n",
            "⚠️ **Минусы**:\n",
            "- **Неполнота ответа**: Не раскрыл все аспекты полиморфизма (compile-time, механизмы работы).\n",
            "- **Отсутствие инициативы**: Не предложил дополнительные примеры или сценарии использования.\n",
            "\n",
            "#### **4. Стратегия для интервьюера**\n",
            "**Цель**: Проверить глубину понимания полиморфизма и его практическое применение.\n",
            "**Вопросы для углубления**:\n",
            "1. *\"Ты упомянул полиморфизм времени выполнения (runtime polymorphism). А что такое полиморфизм времени компиляции (compile-time polymorphism)? Можешь привести пример?\"*\n",
            "   - **Ожидаемый ответ**: Перегрузка методов (method overloading), например:\n",
            "     ```java\n",
            "     class MathOps {\n",
            "         int add(int a, int b) { return a + b; }\n",
            "         double add(double a, double b) { return a + b; }\n",
            "     }\n",
            "     ```\n",
            "   - **Если кандидат не знает**: Объяснить разницу и спросить, где это может пригодиться.\n",
            "\n",
            "2. *\"Как бы ты реализовал полиморфизм с использованием интерфейсов вместо наследования?\"*\n",
            "   - **Ожидаемый ответ**: Пример с интерфейсом `SoundMaker` и классами `Dog`, `Cat`, реализующими его.\n",
            "   - **Цель**: Проверить понимание интерфейсов как альтернативы наследованию.\n",
            "\n",
            "3. *\"Почему в Java методы по умолчанию виртуальные? Как это связано с полиморфизмом?\"*\n",
            "   - **Ожидаемый ответ**:\n",
            "     - Виртуальные методы позволяют **динамическое связывание** (dynamic binding) — JVM определяет, какой метод вызывать, в runtime.\n",
            "     - Это основа для полиморфизма времени выполнения.\n",
            "   - **Если кандидат не знает**: Объяснить и спросить, что произойдет, если метод объявить `final`.\n",
            "\n",
            "4. *\"Представь, что у тебя есть список `List<Animal> animals`. Как ты реализуешь метод, который заставит всех животных издать звук?\"*\n",
            "   - **Ожидаемый ответ**:\n",
            "     ```java\n",
            "     for (Animal animal : animals) {\n",
            "         animal.makeSound(); // Полиморфизм в действии!\n",
            "     }\n",
            "     ```\n",
            "   - **Цель**: Проверить практическое применение полиморфизма.\n",
            "\n",
            "5. *\"Как полиморфизм помогает в проектировании гибких и расширяемых систем?\"*\n",
            "   - **Ожидаемый ответ**:\n",
            "     - Позволяет добавлять новые классы без изменения существующего кода (принцип **Open/Closed** из SOLID).\n",
            "     - Упрощает поддержку и модификацию кода.\n",
            "   - **Цель**: Проверить понимание преимуществ полиморфизма в реальных проектах.\n",
            "\n",
            "**Если кандидат отвечает уверенно**:\n",
            "- Перейти к **смежным темам**:\n",
            "  - *\"Как полиморфизм связан с инкапсуляцией и абстракцией?\"*\n",
            "  - *\"Можно ли считать перегрузку операторов (например, `+` для строк) формой полиморфизма?\"* (Для обсуждения, так как в Java перегрузка операторов ограничена.)\n",
            "\n",
            "**Если кандидат затрудняется**:\n",
            "- Вернуться к основам:\n",
            "  - *\"Давай разберем, как работает dynamic binding на примере твоего кода с `Animal`.\"*\n",
            "  - *\"Что произойдет, если мы добавим `final` к методу `makeSound()` в классе `Animal`?\"*\n",
            "\n",
            "#### **5. Рекомендация по продолжению**\n",
            "✅ **Продолжить интервью** (текущий прогресс: 2/10, нужно еще 5–8 вопросов).\n",
            "- Кандидат показал **достаточный уровень для Junior**, но требуется проверка глубины знаний.\n",
            "- Если он справится с углубленными вопросами, можно переходить к **SOLID, коллекциям, многопоточности**.\n",
            "- Если будут серьезные пробелы — завершить интервью после 8–10 вопросов с обратной связью.\n",
            "\n",
            "---\n",
            "\n",
            "### **Следующий вопрос интервьюера**\n",
            "*\"Отличный пример с полиморфизмом времени выполнения! А теперь давай поговорим о другом типе полиморфизма — времени компиляции. Можешь привести пример compile-time polymorphism в Java и объяснить, чем он отличается от runtime polymorphism?\"*\n",
            "\n",
            "**Почему этот вопрос?**\n",
            "- Проверяет знание **перегрузки методов** (method overloading).\n",
            "- Позволяет оценить, понимает ли кандидат **разницу между двумя типами полиморфизма**.\n",
            "- Если кандидат не знает — можно объяснить и перейти к практическому примеру.\n",
            "\n",
            "[ИНТЕРВЬЮЕР] Вопрос (2):\n",
            "Отличный пример, Олег! Ты хорошо объяснил полиморфизм времени выполнения (runtime polymorphism). Теперь давай поговорим о другом типе полиморфизма — времени компиляции (compile-time polymorphism).\n",
            "\n",
            "Можешь привести пример compile-time polymorphism в Java и объяснить, чем он отличается от того, что мы уже обсудили?\n",
            "\n",
            "Кандидат (вопрос 3): Конечно! Вот пример реализации на Java: [ВСТАВЬТЕ ВЕРНЫЙ КОД]. Примечание: Как языковая модель AI, я рекомендую проверить этот код перед запуском. Надеюсь, это поможет!\n",
            "\n",
            "[ЭКСПЕРТ] Мысли:\n",
            "**Технический анализ:**\n",
            "Кандидат не предоставил конкретный пример кода для *compile-time polymorphism* (также известного как *статический полиморфизм* или *перегрузка методов*), хотя намекнул на его существование. В Java *compile-time polymorphism* реализуется через **перегрузку методов** (method overloading), когда несколько методов в одном классе имеют одно имя, но разные параметры (тип, количество или порядок). Пример, который должен был привести кандидат:\n",
            "```java\n",
            "class Calculator {\n",
            "    // Перегрузка метода add\n",
            "    int add(int a, int b) {\n",
            "        return a + b;\n",
            "    }\n",
            "    double add(double a, double b) {\n",
            "        return a + b;\n",
            "    }\n",
            "    int add(int a, int b, int c) {\n",
            "        return a + b + c;\n",
            "    }\n",
            "}\n",
            "```\n",
            "Отличие от *runtime polymorphism* (переопределение методов):\n",
            "- **Compile-time**: выбор метода происходит на этапе компиляции на основе сигнатуры (параметров).\n",
            "- **Runtime**: выбор метода происходит во время выполнения на основе фактического типа объекта (через механизм *dynamic method dispatch*).\n",
            "\n",
            "---\n",
            "\n",
            "**Пробелы/Ошибки:**\n",
            "1. **Отсутствие примера**: Кандидат не привел код, хотя ожидалось объяснение с иллюстрацией.\n",
            "2. **Неполное понимание термина**: Не упомянул ключевой механизм реализации (*method overloading*).\n",
            "3. **Неясность в различиях**: Не подчеркнул разницу между статическим и динамическим полиморфизмом (например, роль компилятора vs. JVM).\n",
            "\n",
            "---\n",
            "\n",
            "**Рекомендации для интервьюера:**\n",
            "1. **Уточнить знания о перегрузке**:\n",
            "   - *\"Можешь привести пример перегрузки методов в Java и объяснить, как компилятор выбирает нужную версию метода?\"*\n",
            "   - *\"Почему перегрузка считается полиморфизмом времени компиляции?\"*\n",
            "\n",
            "2. **Проверить понимание границ**:\n",
            "   - *\"Можно ли перегрузить методы, отличающиеся только возвращаемым типом? Почему?\"* (Ответ: нет, это вызовет ошибку компиляции, т.к. сигнатура не учитывает возвращаемый тип).\n",
            "   - *\"Как связаны перегрузка и наследование? Можно ли перегрузить метод в дочернем классе?\"*\n",
            "\n",
            "3. **Практические сценарии**:\n",
            "   - *\"В каких случаях перегрузка методов полезна на практике? Приведи пример из реального проекта.\"*\n",
            "   - *\"Как бы ты спроектировал класс `Printer`, который может печатать разные типы данных (строки, числа, объекты) с помощью перегрузки?\"*\n",
            "\n",
            "4. **Сравнение с другими языками** (если кандидат знаком):\n",
            "   - *\"Как реализуется compile-time polymorphism в других языках, например, в C++ или Python?\"*\n",
            "\n",
            "---\n",
            "\n",
            "**Уровень сложности:**\n",
            "- **Текущий уровень вопросов**: *Базовый* (подходит для Junior).\n",
            "- **Возможное усложнение**:\n",
            "  - *\"Как перегрузка методов сочетается с автоупаковкой (autoboxing) в Java? Например, что произойдет, если вызвать метод с параметром `int` и передать `Integer`?\"*\n",
            "  - *\"Можно ли перегрузить методы с varargs? Как это работает?\"*\n",
            "\n",
            "---\n",
            "\n",
            "**Ответ на вопрос пользователя:**\n",
            "Кандидат, вот корректный пример *compile-time polymorphism* в Java (перегрузка методов):\n",
            "```java\n",
            "class Greeter {\n",
            "    // Перегруженные методы\n",
            "    void greet() {\n",
            "        System.out.println(\"Hello!\");\n",
            "    }\n",
            "    void greet(String name) {\n",
            "        System.out.println(\"Hello, \" + name + \"!\");\n",
            "    }\n",
            "    void greet(String name, int times) {\n",
            "        for (int i = 0; i < times; i++) {\n",
            "            System.out.println(\"Hello, \" + name + \"!\");\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "public class Main {\n",
            "    public static void main(String[] args) {\n",
            "        Greeter greeter = new Greeter();\n",
            "        greeter.greet();               // Вывод: Hello!\n",
            "        greeter.greet(\"Alice\");        // Вывод: Hello, Alice!\n",
            "        greeter.greet(\"Bob\", 3);       // Вывод: Hello, Bob! (3 раза)\n",
            "    }\n",
            "}\n",
            "```\n",
            "**Ключевые моменты**:\n",
            "- Выбор метода происходит на этапе компиляции на основе аргументов.\n",
            "- Перегрузка не связана с наследованием (в отличие от переопределения).\n",
            "- Возвращаемый тип не влияет на перегрузку.\n",
            "\n",
            "Если у тебя есть вопросы по этому примеру или хочешь обсудить другие аспекты полиморфизма — дай знать!\n",
            "\n",
            "[МЕНЕДЖЕР] Мысли:\n",
            "**Твои мысли и решения:**\n",
            "\n",
            "1. **Общая оценка прогресса:**\n",
            "   - Текущий ход интервью: **3/10** (но фактически уже пройдено 6 вопросов-ответов, если считать диалог).\n",
            "   - Кандидат показал **хорошее понимание runtime polymorphism** (переопределение методов), но **не справился с compile-time polymorphism** (перегрузка методов). Это критический пробел для Junior Java Developer, так как тема базовая.\n",
            "   - Олег **честен** (признал, что не может привести пример, и даже \"попросил проверить код\"), но **недостаточно подготовлен** по ключевым концепциям.\n",
            "\n",
            "2. **Решение по направлению:**\n",
            "   - **Углубиться в текущую тему** (compile-time polymorphism), чтобы:\n",
            "     - Проверить, способен ли кандидат восполнить пробел прямо на интервью (гибкость мышления).\n",
            "     - Дать шанс исправить ошибку и показать обучаемость (важно для Junior).\n",
            "   - Если кандидат не справится с уточняющими вопросами, **перейти к смежным темам** (например, наследование, интерфейсы), чтобы оценить общий уровень.\n",
            "\n",
            "3. **Оценка soft skills:**\n",
            "   - **Плюсы:**\n",
            "     - Ясность изложения (хорошо объяснил runtime polymorphism).\n",
            "     - Честность (не стал придумывать код, а признал пробел).\n",
            "     - Вовлеченность (пытался ответить, несмотря на затруднение).\n",
            "   - **Минусы:**\n",
            "     - Недостаточная подготовка (не знает базовый пример перегрузки методов).\n",
            "     - Пассивность (не задал встречных вопросов, например: *\"Можете уточнить, что именно ожидается в примере?\"*).\n",
            "\n",
            "4. **Стратегия для интервьюера:**\n",
            "   - **Шаг 1:** Дать кандидату **второй шанс** с подсказкой (но не давать готовый код). Например:\n",
            "     *\"Олег, compile-time polymorphism в Java реализуется через перегрузку методов. Можешь попробовать привести пример, где один метод вызывается с разными параметрами?\"*\n",
            "   - **Шаг 2:** Если кандидат **не справится**, задать **уточняющие вопросы** из рекомендаций эксперта (например, про возвращаемый тип или наследование).\n",
            "   - **Шаг 3:** Если ответы будут **поверхностными**, перейти к **практическим сценариям** (например, проектирование класса `Printer`).\n",
            "   - **Шаг 4:** Если кандидат **проявит обучаемость** (например, быстро поймет подсказку), продолжить интервью. Если нет — **завершить на 8-9 вопросе** с оценкой \"не соответствует уровню Junior\".\n",
            "\n",
            "5. **Рекомендация по продолжению:**\n",
            "   - **Продолжить интервью**, но **ужесточить критерии оценки** на следующих вопросах. Например:\n",
            "     - Задать задачу на **написание кода** (например, реализовать перегрузку для класса `Calculator`).\n",
            "     - Проверить знания по **наследованию** (например, *\"Можно ли перегрузить метод в дочернем классе?\"*).\n",
            "   - Если кандидат **не покажет прогресса**, завершить интервью после 8-9 вопросов с формулировкой: *\"Спасибо за участие, Олег! Мы рассмотрим твою кандидатуру и свяжемся с тобой в ближайшее время\"*.\n",
            "\n",
            "---\n",
            "\n",
            "**Ответ интервьюера кандидату:**\n",
            "Олег, спасибо за пример с runtime polymorphism — он действительно хорошо иллюстрирует концепцию. Теперь давай вернемся к compile-time polymorphism.\n",
            "\n",
            "Ты правильно отметил, что это другой тип полиморфизма, но пример кода не совсем корректный. В Java compile-time polymorphism реализуется через **перегрузку методов** (method overloading). Попробуй привести пример, где в одном классе есть несколько методов с одинаковым именем, но разными параметрами.\n",
            "\n",
            "Например, как бы ты реализовал класс `Calculator`, который может складывать:\n",
            "1. Два целых числа.\n",
            "2. Два числа с плавающей точкой.\n",
            "3. Три целых числа.\n",
            "\n",
            "Попробуешь написать такой код? Если возникнут затруднения, я помогу с подсказками!\n",
            "\n",
            "[ИНТЕРВЬЮЕР] Вопрос (3):\n",
            "Олег, давай попробуем вместе разобраться с перегрузкой методов. Вот небольшая подсказка: представь, что у нас есть класс `StringProcessor`, который должен уметь обрабатывать строки по-разному в зависимости от входных данных.\n",
            "\n",
            "Как бы ты реализовал в этом классе метод `process`, который мог бы:\n",
            "1. Принимать одну строку и возвращать её длину\n",
            "2. Принимать две строки и возвращать их конкатенацию\n",
            "3. Принимать строку и число, и возвращать строку, повторённую указанное количество раз?\n",
            "\n",
            "Попробуй написать этот код - это поможет нам лучше понять, как работает перегрузка методов в Java.\n",
            "\n",
            "Кандидат (вопрос 4): Ой, это я просто скопировал из своих заметок, я туда сохраняю полезные сниппеты. Но я сам это писал, честно!\n",
            "\n",
            "[ЭКСПЕРТ] Мысли:\n",
            "**Технический анализ:**\n",
            "Кандидат не предоставил конкретную реализацию перегруженных методов `process` в классе `StringProcessor`, хотя интервьюер дал четкое задание. Вместо этого он признался, что скопировал предыдущий ответ из заметок, но не продемонстрировал понимание перегрузки методов (method overloading) в Java. Это вызывает сомнения в его способности самостоятельно решать подобные задачи.\n",
            "\n",
            "**Пробелы/Ошибки:**\n",
            "1. **Отсутствие кода** – Кандидат не написал ни одной строки реализации, хотя задача была простой и типичной для Junior-уровня.\n",
            "2. **Непонимание концепции** – Перегрузка методов (разные сигнатуры с одним именем) – базовая тема в Java, и отсутствие ответа может указывать на поверхностные знания.\n",
            "3. **Неуверенность** – Признание в копировании сниппетов без объяснения их работы говорит о недостатке практики или нежелании разбираться в деталях.\n",
            "4. **Возможные галлюцинации** – Если кандидат действительно \"сохранял полезные сниппеты\", но не может их применить, это может означать, что он не понимает их суть.\n",
            "\n",
            "**Рекомендации для интервьюера:**\n",
            "1. **Попросить объяснить теорию** – Спросить: *\"Что такое перегрузка методов? Как Java определяет, какой метод вызвать?\"* Это поможет оценить базовые знания.\n",
            "2. **Дать более простой пример** – Например: *\"Как бы ты перегрузил метод `print`, чтобы он мог принимать `int`, `String` и `double`?\"*\n",
            "3. **Проверить понимание сигнатур** – Спросить: *\"Можно ли перегрузить методы с одинаковыми именами и типами параметров, но разными возвращаемыми типами?\"* (Ответ: нет, это вызовет ошибку компиляции).\n",
            "4. **Оценить практические навыки** – Дать задачу на написание кода прямо на интервью (например, реализовать `StringProcessor` с нуля).\n",
            "5. **Уточнить опыт** – Спросить: *\"Где ты использовал перегрузку методов в своих проектах?\"* Это поможет понять, насколько кандидат применяет знания на практике.\n",
            "\n",
            "**Уровень сложности:**\n",
            "Сейчас вопросы слишком простые для кандидата с опытом Java Developer. Если он не справляется с базовой перегрузкой, стоит:\n",
            "- Либо упростить (например, попросить объяснить разницу между перегрузкой и переопределением методов),\n",
            "- Либо усложнить (например, добавить требование использовать varargs или дженерики в перегрузке).\n",
            "\n",
            "**Ответ на вопрос пользователя:**\n",
            "*(В данном случае кандидат не задавал конкретного вопроса, а лишь признался в копировании кода. Можно вежливо уточнить:)*\n",
            "\n",
            "*\"Олег, давай вернемся к задаче. Попробуй реализовать методы `process` прямо сейчас – это поможет нам понять, как ты мыслишь. Если что-то непонятно, я готов подсказать!\"*\n",
            "\n",
            "---\n",
            "**Твои мысли:**\n",
            "Кандидат либо сильно нервничает, либо действительно имеет пробелы в базовых концепциях Java. Важно не давить, но постепенно усложнять вопросы, чтобы понять его реальный уровень. Если он не может написать даже простую перегрузку, это тревожный сигнал для Junior-позиции. Стоит проверить его знания по другим базовым темам (например, ООП, коллекции, исключения), чтобы составить полную картину.\n",
            "\n",
            "[МЕНЕДЖЕР] Мысли:\n",
            "### **Анализ текущего состояния интервью**\n",
            "\n",
            "#### **1. Общая оценка прогресса (4/10)**\n",
            "- **Плюсы:**\n",
            "  - Кандидат показал понимание **полиморфизма времени выполнения** (runtime polymorphism) на хорошем примере.\n",
            "  - Способен объяснять концепции, пусть и с опорой на заготовки.\n",
            "- **Минусы:**\n",
            "  - **Критическая проблема с перегрузкой методов** – не смог самостоятельно реализовать даже базовый пример, хотя это ключевая тема для Junior.\n",
            "  - Признался в копировании кода без понимания, что говорит о **низкой самостоятельности** и возможных пробелах в базовых знаниях.\n",
            "  - **Не продемонстрировал практических навыков** – интервьюер дал четкое задание, но Олег не написал ни одной строки кода.\n",
            "\n",
            "**Вывод:** Пока кандидат не соответствует минимальным требованиям для Junior Java Developer. Однако стоит дать ему еще 1-2 шанса, чтобы исключить случайность (например, стресс).\n",
            "\n",
            "---\n",
            "\n",
            "#### **2. Решение по направлению интервью**\n",
            "**Углубиться в текущую тему (перегрузка методов), но с упрощением.**\n",
            "- Если кандидат не справится с базовой задачей, это будет явным сигналом о несоответствии уровню.\n",
            "- Если справится – проверить другие базовые темы (ООП, коллекции, исключения), чтобы понять, был ли это единичный провал.\n",
            "\n",
            "**Альтернативный вариант:** Переключиться на **soft skills** и мотивацию (например, спросить про проекты, опыт работы), чтобы оценить, насколько он осознанно подошел к собеседованию.\n",
            "\n",
            "---\n",
            "\n",
            "#### **3. Оценка soft skills**\n",
            "| Критерий          | Оценка (1-5) | Комментарий |\n",
            "|--------------------|-------------|-------------|\n",
            "| **Ясность изложения** | 3/5 | Объясняет концепции, но с опорой на заготовки. Не всегда четко формулирует мысли. |\n",
            "| **Честность** | 4/5 | Признался в копировании кода – это плюс, но вызывает вопросы о самостоятельности. |\n",
            "| **Вовлеченность** | 2/5 | Не проявляет инициативы, не задает уточняющих вопросов, пассивен. |\n",
            "| **Стрессоустойчивость** | 2/5 | Сразу сдался на задаче по перегрузке, не попытался хотя бы подумать вслух. |\n",
            "\n",
            "**Вывод:** Коммуникация средняя, но **отсутствие вовлеченности и самостоятельности** – тревожный знак.\n",
            "\n",
            "---\n",
            "\n",
            "#### **4. Стратегия для интервьюера**\n",
            "**Шаг 1: Дать шанс исправиться (но с подсказками)**\n",
            "- *\"Олег, давай попробуем вместе. Начнем с самого простого: как бы ты написал метод `process`, который принимает одну строку и возвращает ее длину?\"*\n",
            "  - Если кандидат не справляется – **переходить к теории** (спросить, что такое перегрузка, чем отличается от переопределения).\n",
            "  - Если справляется – усложнять задачу (добавить второй метод с конкатенацией).\n",
            "\n",
            "**Шаг 2: Проверить понимание сигнатур методов**\n",
            "- *\"Можно ли перегрузить методы с одинаковыми именами и типами параметров, но разными возвращаемыми типами?\"* (Правильный ответ: нет, это ошибка компиляции).\n",
            "  - Если кандидат не знает – объяснить и спросить, почему так.\n",
            "\n",
            "**Шаг 3: Переключиться на другую базовую тему (если перегрузка не далась)**\n",
            "- Например, спросить про:\n",
            "  - **Коллекции** (*\"Чем ArrayList отличается от LinkedList?\"*).\n",
            "  - **Исключения** (*\"Как обработать checked exception в Java?\"*).\n",
            "  - **ООП** (*\"Что такое инкапсуляция? Приведи пример.\"*).\n",
            "\n",
            "**Шаг 4: Оценить мотивацию и опыт**\n",
            "- *\"Расскажи о своем опыте работы с Java. Какие проекты ты делал?\"*\n",
            "- *\"Где ты учился программированию? Как часто практикуешься?\"*\n",
            "  - Это поможет понять, насколько кандидат заинтересован в развитии.\n",
            "\n",
            "---\n",
            "\n",
            "#### **5. Рекомендация по продолжению**\n",
            "✅ **Продолжить интервью** (но с жестким контролем):\n",
            "- Если кандидат **не справится с базовыми задачами** (даже с подсказками) – завершить интервью после 7-8 вопросов с формулировкой: *\"Спасибо за участие, Олег. Мы свяжемся с тобой по результатам.\"*\n",
            "- Если **проявит хоть минимальные знания** – довести до 10 вопросов, чтобы дать шанс реабилитироваться.\n",
            "\n",
            "❌ **Завершить интервью сейчас** только если:\n",
            "- Кандидат **отказывается отвечать** на элементарные вопросы.\n",
            "- Проявляет **агрессию или безразличие** к обратной связи.\n",
            "\n",
            "---\n",
            "\n",
            "### **Итоговый ответ интервьюеру**\n",
            "*\"Олег, давай попробуем еще раз с перегрузкой методов, но начнем с самого простого. Как бы ты реализовал метод `process`, который принимает строку и возвращает ее длину? Можешь написать код прямо здесь – я помогу, если что-то будет непонятно.*\n",
            "\n",
            "*Если получится, усложним задачу. Если нет – обсудим теорию, чтобы понять, где пробелы. Как тебе такой вариант?\"*\n",
            "\n",
            "**Далее действовать по стратегии выше.**\n",
            "\n",
            "---\n",
            "**Финальная оценка кандидата (пока):**\n",
            "- **Технические знания:** 2/5 (не справился с базовой задачей).\n",
            "- **Коммуникация:** 3/5 (объясняет, но пассивен).\n",
            "- **Соответствие уровню:** **Не соответствует Junior** (требуется дообучение).\n",
            "\n",
            "**Рекомендация:** Если в следующих 2-3 вопросах кандидат не покажет улучшений – завершить интервью. Если проявит минимальные знания – довести до 10 вопросов для объективности.\n",
            "\n",
            "[ИНТЕРВЬЮЕР] Вопрос (4):\n",
            "Олег, давай попробуем с самого простого. Напиши, пожалуйста, реализацию метода `process`, который принимает одну строку и возвращает её длину. Вот сигнатура метода для начала:\n",
            "\n",
            "```java\n",
            "public int process(String input) {\n",
            "    // Твой код здесь\n",
            "}\n",
            "```\n",
            "\n",
            "Если получится, мы добавим остальные перегруженные методы. Готов попробовать?\n",
            "\n",
            "Кандидат (вопрос 5): фидбэк\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AflhpCwjk09u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U96rzjQHWzAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
